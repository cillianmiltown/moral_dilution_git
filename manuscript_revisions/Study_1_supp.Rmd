---
title             : "Study 1"
shorttitle        : "Moral Dilution"
author:
  - name          : "Blinded"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Blinded"
    email         : "Blinded"
  - name          : "Blinded"
    affiliation   : "2"
  - name          : "Blinded"
    affiliation   : "1"
  - name          : "Blinded"
    affiliation   : "1"
affiliation:
  - id            : "1"
    institution   : "Blinded"
  - id            : "2"
    institution   : "Blinded"
author_note: >
  All procedures performed in studies involving human participants were approved by institutional research ethics committee and conducted in accordance with the Code of Professional Ethics of the Psychological Society of Ireland, and with the 1964 Helsinki declaration and its later amendments or comparable ethical standards. Informed consent was obtained from all individual participants included in the study. The authors declare that there are no potential conflicts of interest with respect to the research, authorship, and/or publication of this article. All authors consented to the submission of this manuscript.
abstract: >
  Six studies etc.
keywords          : "keywords"
wordcount         : "TBC"
bibliography: "../resources/bib/My Library.bib"
csl: "../resources/bib/apa6.csl"
figsintext        : true
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
toc               : false
lang              : "en-US"
documentclass     : "apa6"
output:
  papaja::apa6_pdf
header-includes:
- \raggedbottom
editor_options: 
  chunk_output_type: console
---


```{r S1setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include = FALSE)
# knitr::opts_chunk$set(eval = TRUE, echo = TRUE)
#knitr::opts_chunk$set(include = FALSE)
```


```{r S1load_libraries_cogload}
rm(list = ls())
library(citr)
#install.packages("sjstats")
library(plyr)
library(foreign)
library(car)
library(desnum)
library(ggplot2)
library(extrafont)
#devtools::install_github("crsh/papaja")
library(papaja)
#library("dplyr")
library("afex")
library("tibble")
library(scales)
#install.packages("metap")
library(metap)
library(pwr)
library(lsr)
#install.packages("sjstats")
library(sjstats)
library(DescTools)
#inatall.packages("ggstatsplot")
#library(ggstatsplot)
library(VGAM)
library(nnet)
library(mlogit)
library(reshape2)
#install.packages("powerMediation")
library("powerMediation")
library("ggpubr")


# library(rstatix)


#source("load_all_data.R")

#devtools::install_github("benmarwick/wordcountaddin")
#library(wordcountaddin)
#wordcountaddin::text_stats("cogload_1to5_25Sept19.Rmd")
#setwd("manuscript_prep")
getwd()
```


## Study 1: T-tests


```{r}
df1 <- read.csv("../data/study1_data_long.csv")
df3 <- read.csv("../data/study1_data_long_clean.csv")
table(df3$gender)
length(df1$gender)/6
length(levels(as.factor(df1$ResponseId)))-length(levels(as.factor(df3$ResponseId)))
length(df3$gender)/4

att_both <- length(levels(as.factor(df1$ResponseId)))-length(levels(as.factor(df3$ResponseId)))
```


```{r}


x <- df3
x <- x[order(x$ResponseId),]

diag <- x[which(x$condition=="diagnostic"),]
non_diag <- x[which(x$condition=="non-diagnostic"),]

test <- cbind.data.frame(
  diag$ResponseId
  ,non_diag$ResponseId
  ,diag$R_tot
  ,non_diag$R_tot)

test <- 
  `colnames<-`(test
               ,c(
                 "ID1"
                 ,"ID2"
                 ,"DV1"
                 ,"DV2"
               ))

t1 <- t.test(test$DV1,test$DV2, paired = T)
d1 <- cohensD(test$DV1,test$DV2)

t1$statistic
t1$parameter
t1$p.value
d1
t1$conf.int[1]
t1$conf.int[2]

desnum::t_paired_paragraph(test$DV1,test$DV2, "DV")

```

A paired samples t-test indicated that there were significant differences in MPS-4 responses depending on information type
*t*(`r t1$parameter`),
= `r t1$statistic`,
*p* `r paste(p_report(t1$p.value))`
*d* = `r d1`,
95% CI [`r t1$conf.int[1]`, `r t1$conf.int[2]`].
MPS-4 responses were higher in the non-diagnostic condition
(*M* = `r mean(test$DV2)`,
*SD* = `r sd(test$DV2)`)
compared to the diagnostic condition
(*M* = `r mean(test$DV1)`,
*SD* = `r sd(test$DV1)`).



```{r}


x <- df3
x <- x[order(x$ResponseId),]

diag <- x[which(x$condition=="diagnostic"),]
non_diag <- x[which(x$condition=="non-diagnostic"),]

test <- cbind.data.frame(
  diag$ResponseId
  ,non_diag$ResponseId
  ,diag$M1
  ,non_diag$M1)

test <- 
  `colnames<-`(test
               ,c(
                 "ID1"
                 ,"ID2"
                 ,"DV1"
                 ,"DV2"
               ))

t1 <- t.test(test$DV1,test$DV2, paired = T)
d1 <- cohensD(test$DV1,test$DV2)

t1$statistic
t1$parameter
t1$p.value
d1
t1$conf.int[1]
t1$conf.int[2]

desnum::t_paired_paragraph(test$DV1,test$DV2, "DV")

```

A paired samples t-test indicated that there were significant differences in MM1 responses depending on information type
*t*(`r t1$parameter`),
= `r t1$statistic`,
*p* `r paste(p_report(t1$p.value))`
*d* = `r d1`,
95% CI [`r t1$conf.int[1]`, `r t1$conf.int[2]`].
MM-1 responses were higher in the non-diagnostic condition
(*M* = `r mean(test$DV2)`,
*SD* = `r sd(test$DV2)`)
compared to the diagnostic condition
(*M* = `r mean(test$DV1)`,
*SD* = `r sd(test$DV1)`).


## Study 1: Descriptives for Each Scenario



```{r}
df1 <- read.csv("../data/study1_data_long.csv")
df3 <- read.csv("../data/study1_data_long_clean.csv")
table(df3$gender)
length(df1$gender)/6
length(levels(as.factor(df1$ResponseId)))-length(levels(as.factor(df3$ResponseId)))
length(df3$gender)/4

att_both <- length(levels(as.factor(df1$ResponseId)))-length(levels(as.factor(df3$ResponseId)))
```




```{r}
x <- df3
sam <- x[which(x$scenario=="sam"),]
francis <- x[which(x$scenario=="francis"),]
alex <- x[which(x$scenario=="alex"),]
robin <- x[which(x$scenario=="robin"),]

```

```{r}
x <- df3
# bad <- x[which(x$condition=="diagnostic"),]
# good <- x[which(x$condition=="non-diagnostic"),]
#good$scenario_abb <- droplevels(good$scenario_abb)

#x <- bad
aov_full <- rstatix::anova_test(
  data=x
  , dv=R_tot
  , wid = ResponseId
  , within = scenario)
aov1 <- rstatix::get_anova_table(aov_full)
aov1
aov1$DFd

pwc <- x %>%
  rstatix::pairwise_t_test(
    R_tot ~ scenario, paired = TRUE,
    p.adjust.method = "bonferroni"
    )
pwc
p_report(pwc$p[2])

# d1 <- lsr::cohensD(R_tot~condition,x,method="paired")
# t.test(R_tot~condition,x,paired=TRUE)
# t1 <- t.test(x$R_tot~x$scenario,paired=TRUE)
# d1
lapply(pwc$p.adj,p_report)
```




The means and standard deviations for MPS-4 for each scenario are as follows: 
*Sam*,
*M*~MPS-4~ = `r mean(sam$R_tot)`, *SD*~MPS-4~ = `r sd(sam$R_tot)`,
*Francis*,
*M*~MPS-4~ = `r mean(francis$R_tot)`, *SD*~MPS-4~ = `r sd(francis$R_tot)`,
*Alex*,
*M*~MPS-4~ = `r mean(alex$R_tot)`, *SD*~MPS-4~ = `r sd(alex$R_tot)`,
*Robin*,
*M*~MPS-4~ = `r mean(robin$R_tot)`, *SD*~MPS-4~ = `r sd(robin$R_tot)`. There was significant variation depending on the description, *F*(`r round(aov1$DFn)`,`r round(aov1$DFd)`) = `r aov1$F`, *p* `r paste(p_report(aov1$p))`, partial $\eta$^2^ = `r aov1$ges`. *Francis* appeared to be rated as more moral than each of the other characters (all *p*s < .001), while *Robin* was rated as less moral than each of the other characters (all *p*s < .001), while *Sam* was rated more favorably than *Alex* (*p* < .001). 



```{r}
x <- df3
# bad <- x[which(x$condition=="diagnostic"),]
# good <- x[which(x$condition=="non-diagnostic"),]
#good$scenario_abb <- droplevels(good$scenario_abb)

#x <- bad
aov_full <- rstatix::anova_test(
  data=x
  , dv=M1
  , wid = ResponseId
  , within = scenario)
aov1 <- rstatix::get_anova_table(aov_full)
aov1
aov1$DFd

pwc <- x %>%
  rstatix::pairwise_t_test(
    M1 ~ scenario, paired = TRUE,
    p.adjust.method = "bonferroni"
    )
pwc
p_report(pwc$p[2])
lapply(pwc$p.adj, p_report)
paste(pwc$p.adj[2])
pwc$p[2]
# d1 <- lsr::cohensD(M1~condition,x,method="paired")
# t.test(M1~scenario,x,paired=TRUE)
# t1 <- t.test(x$M1~x$scenaro,paired=TRUE)
# d1

```

The means and standard deviations for MM-1 for each scenario are as follows: 
*Sam*,
*M*~MM-1~ = `r mean(sam$M1)`, *SD*~MM-1~ = `r sd(sam$M1)`;
*Francis*,
*M*~MM-1~ = `r mean(francis$M1)`, *SD*~MM-1~ = `r sd(francis$M1)`;
*Alex*,
*M*~MM-1~ = `r mean(alex$M1)`, *SD*~MM-1~ = `r sd(alex$M1)`;
*Robin*,
*M*~MM-1~ = `r mean(robin$M1)`, *SD*~MM-1~ = `r sd(robin$M1)`. There was significant variation depending on the description, *F*(`r round(aov1$DFn)`,`r round(aov1$DFd)`) = `r aov1$F`, *p* `r paste(p_report(aov1$p))`, partial $\eta$^2^ = `r paste(aov1$ges)`. *Francis* was rated more favorably than all other characters (*p* < .001), *Sam* was the next most favorably rated character, rated significantly more favorably than both *Alex* and *Robin* (*p*s < .001), there was no difference between *Alex* and *Robin* (*p* = `r paste(p_report(pwc$p[2]))`).



## Study 1: Combined Measure

We developed a combined moral perception measure by calculating the mean of the combined mean-centered scores for MPS-4 and MM-1, and mean-centering this result. Below we report the analyses for this combined measure.

```{r}
df1 <- read.csv("../data/study1_data_long.csv")
df3 <- read.csv("../data/study1_data_long_clean.csv")
table(df3$gender)
length(df1$gender)/6
length(levels(as.factor(df1$ResponseId)))-length(levels(as.factor(df3$ResponseId)))
length(df3$gender)/4

att_both <- length(levels(as.factor(df1$ResponseId)))-length(levels(as.factor(df3$ResponseId)))
```




```{r}
x <- df3
sam <- x[which(x$scenario=="sam"),]
francis <- x[which(x$scenario=="francis"),]
alex <- x[which(x$scenario=="alex"),]
robin <- x[which(x$scenario=="robin"),]

```

```{r}
x <- df3
# bad <- x[which(x$condition=="diagnostic"),]
# good <- x[which(x$condition=="non-diagnostic"),]
#good$scenario_abb <- droplevels(good$scenario_abb)

#x <- bad
aov_full <- rstatix::anova_test(
  data=x
  , dv=M1R_tot
  , wid = ResponseId
  , within = scenario)
aov1 <- rstatix::get_anova_table(aov_full)
aov1
aov1$DFd

pwc <- x %>%
  rstatix::pairwise_t_test(
    R_tot ~ scenario, paired = TRUE,
    p.adjust.method = "bonferroni"
    )
pwc
p_report(pwc$p[2])

# d1 <- lsr::cohensD(R_tot~condition,x,method="paired")
# t.test(R_tot~condition,x,paired=TRUE)
# t1 <- t.test(x$R_tot~x$scenario,paired=TRUE)
# d1
lapply(pwc$p.adj,p_report)
```


The means and standard deviations for the combined measure for each scenario are as follows: 
*Sam*,
*M* = `r mean(sam$M1R_tot)`, *SD* = `r sd(sam$M1R_tot)`,
*Francis*,
*M* = `r mean(francis$M1R_tot)`, *SD* = `r sd(francis$M1R_tot)`,
*Alex*,
*M* = `r mean(alex$M1R_tot)`, *SD* = `r sd(alex$M1R_tot)`,
*Robin*,
*M* = `r mean(robin$M1R_tot)`, *SD* = `r sd(robin$M1R_tot)`. There was significant variation depending on the description, *F*(`r round(aov1$DFn)`,`r round(aov1$DFd)`) = `r aov1$F`, *p* `r paste(p_report(aov1$p))`, partial $\eta$^2^ = `r aov1$ges`. *Francis* appeared to be rated as the most favorable, followed by *Sam*, then *Alex* and finally *Robin* as the least favorable (all *p*s < .001). 



```{r}
x <- df3
model0 <- lmerTest::lmer(M1R_tot ~ 1
                #   condition
                 + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
          #      , contrasts = list(condition = contr.sum  , valence = contr.sum)
            )

summary(model0)
model1 <- lmerTest::lmer(M1R_tot ~
                  condition*scenario
                + (1|ResponseId)
                + (1|ResponseId:condition)
                , data = x
                , contrasts = list(condition = contr.sum  )#, valence = contr.sum)
            )

results_anova <- as.data.frame(anova(model0,model1))
results_anova
results_anova$Chisq[2]
results_anova$Df
p1 <- results_anova$`Pr(>Chisq)`[2]
p_report(p1)
#p_report(results_anova$`Pr(>Chisq)`)[2]
results_anova$AIC
summary_model1 <- summary(model1)
summary_model1
results_coef <- as.data.frame(summary_model1$coefficients)

aov1 <- anova(model1)
f3 <- aov1$`F value`[1]
p3 <- aov1$`Pr(>F)`[1]

results_coef$Estimate[2]
results_coef$`Std. Error`[2]
results_coef$df[2]
t1 <- results_coef$`t value`[2]
p2 <- results_coef$`Pr(>|t|)`[2]

#QuantPsyc::lm.beta(results_coef)
anova(model1)
```

We conducted a linear-mixed-effects model to test if condition influenced moral perception. Our outcome measure was the combined moral perception measure, our predictor variable was condition; we allowed intercepts and the effect of condition to vary across participants, and scenario was also included in the model.
Overall, the model significantly predicted participants responses, and provided a better fit for the data than the baseline model, $\chi$^2^(`r results_anova$Df[2]`) = `r results_anova$Chisq[2]`, *p* `r paste(p_report(p1))`. Condition significantly influenced responses to the MPS-4, *F*(`r aov1$NumDF[1]`, `r aov1$DenDF[1]`) = `r f3`, *p* `r paste(p_report(p3))`; and was a significant predictor in the model when controlling for scenario, $b$ = `r results_coef$Estimate[2]`, *t*(`r results_coef$df[2]`) = `r t1`, *p* `r paste(p_report(p2))`, with the non-diagnostic descriptions being rated as more moral than the diagnostic (morally relevant) descriptions of immoral characters Figure\ \@ref(fig:S1combinedconditionplot).

```{r}

x_error_bars <- Rmisc::summarySE(x, measurevar="M1R_tot", groupvars=c("condition"
                                                                    #, "Valence"
                                                                    ))
x_error_bars

g <- ggplot(x,
            aes(x = condition, y = M1R_tot
                , fill=factor(condition
                              ,labels=c("Diagnostic","Non-Diagnostic")
                )
               # , color=factor(Valence)
            )) + 
  
  #scale_y_continuous(limits = c(-0, 140))+
  #, labels = percent_format()
  # )+ 
  ggdist::stat_halfeye(
    adjust = .9, 
    width = .15, 
    .width = 0, 
    justification = -.7, 
    point_colour = NA,
    position = position_dodge(width=0.9)
  ) + 
  geom_boxplot(
    width = .13, 
    outlier.shape = NA
    , position = position_dodge(width=.8)
    , show_guide = FALSE
  ) +
  ## add justified jitter from the {gghalves} package
  gghalves::geom_half_point(
    aes(color=factor(condition
                     #                   ,labels=c("Means","Side-Effect")
    )
    ),
    position = position_dodge(width=4.3),
    ## draw jitter on the left
    side = "l", 
    ## control range of jitter
    range_scale = .4, 
    ## add some transparency
    alpha = .42,
    size = .1,
    show_guide = FALSE
  )+
  # stat_summary(
  #   aes(color=factor(Condition
  #                                         #,labels=c("Gratitude","No Gratitude")
  #   )
  #   ),
  #   geom = "point",
  #   fun = "mean",
  #   col = "black",
  #   size = 1,
  #   shape = 16, #24,
  #   position = position_dodge(width=.2)
  #  # , justification = -.2
  #   , fill = "black"
  #   ,show_guide = FALSE
  # )+
  geom_errorbar(data = x_error_bars,aes(ymin=M1R_tot-se
                                        , ymax=M1R_tot+se
                                        , width=.05#, position=pd
                                        # , fill= "black" #factor(condition
                                        #     ,labels=c("Means","Side-Effect")
                                        #)
  )
  , position = position_dodge(width=6.12)
  ) +
  geom_point(data=x_error_bars, inherit.aes = FALSE
             , aes(x=condition, y=M1R_tot)
             , size=.5
    )+
  #facet_grid(cols = vars(means))+
  xlab("Information Type") +
  ylab("Moral Perception (combined)") +
  scale_x_discrete(
    labels=c("Diagnostic","Non-Diagnostic")
  ) +
  scale_y_continuous(limits = c(-2,3.5)
                     , breaks = seq(-2,3.5, by = .5)  #  c(0:)
                     #                    , labels=c(" ", "1", "2", "3","4","5","6","7")
  ) +
  scale_fill_grey(start = .3, end = .6) +
  scale_color_grey(start = .3, end = .6) +
  guides(
    fill=guide_legend(title = "Information Type")
    , color="none" #guide_legend(title="Valence")
    , shape="none"
  )+
  #facet_grid(cols = vars(Valence))+
  #labs(fill="Means/Side-Effect") +
  # 
  # geom_text(#family = "Times",
  #           size=4.2,
  #           aes( label = scales::percent(test$perc),
  #                y= test$perc ),
  #           stat= "identity",
  #           vjust = -.5,
  #           position = position_dodge(.9),
  #           fontface='plain'
  #           )+
#theme_apa() +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        #panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
                                size=12
                                ),
        legend.text=element_text(#family="Times",
                                 size=8
                                 ),
          legend.title=element_text(#family="Times",
                                    size=10
                                    ),
          axis.text=element_text(#family="Times",
                                 colour = "black",
                                 size=8
                                 ),
          axis.ticks.x = element_blank(),
          axis.title=element_text(#family="Times",
                                  size=12
                                  ),
          strip.text=element_text(#family = "Times",
                                  size = 12
                                  ),
         # strip.background = element_rect(fill = "white"),
          legend.position="none")
g


```


```{r S1combinedconditionplot, fig.cap="Study 1: Differences in combined measure depending on condition", include=TRUE, out.width = "\\textwidth", fig.pos = "!h"}

suppressWarnings(print(g))

```

\newpage

## Study 1: Alternative Model



```{r}
x <- df3
model0 <- lmerTest::lmer(R_tot ~ 1
                #   condition
                 + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
          #      , contrasts = list(condition = contr.sum  , valence = contr.sum)
            )

summary(model0)
# model1 <- lmerTest::lmer(R_tot ~
#                   condition*scenario
#                 + (1|ResponseId)
#                 + (1|ResponseId:condition)
#                 , data = x
#                 , contrasts = list(condition = contr.sum  , scenario = contr.sum)
#             )

model1 <- lmerTest::lmer(R_tot ~
                  condition*scenario
                + (1|ResponseId)
                # + (1|ResponseId:condition)
                + (1|scenario)
                , data = x
                , contrasts = list(condition = contr.sum  , scenario = contr.sum)
            )

results_anova <- as.data.frame(anova(model0,model1))
results_anova
results_anova$Chisq[2]
results_anova$Df
p1 <- results_anova$`Pr(>Chisq)`[2]
p_report(p1)
#p_report(results_anova$`Pr(>Chisq)`)[2]
results_anova$AIC
summary_model1 <- summary(model1)
summary_model1
summary_model1$varcor
results_coef <- as.data.frame(summary_model1$coefficients)


aov1 <- anova(model1)
f3 <- aov1$`F value`[1]
p3 <- aov1$`Pr(>F)`[1]

results_coef$Estimate[2]
results_coef$`Std. Error`[2]
results_coef$df[2]
t1 <- results_coef$`t value`[2]
p2 <- results_coef$`Pr(>|t|)`[2]

#QuantPsyc::lm.beta(results_coef)
anova(model1)

d <- (mean(x$R_tot[which(x$condition=="diagnostic")])-mean(x$R_tot[which(x$condition=="non-diagnostic")]))/sd(x$R_tot)

tapply(x$R_tot,x$condition,descriptives)

s_pooled <- sqrt(
  (
    ((.9657055^2)*1601)+((.9594647^2)*1601)
  )/
    (1602+1602-2)
)


s_pooled_fun <- function(){
  
  x$dv <- x$R_tot
  
  z <- 1.959964
  
  df_1 <- x[which(x$condition=="diagnostic"),]
  df_2 <- x[which(x$condition=="non-diagnostic"),]
  
  
  df_1 <- df_1[order(df_1$ResponseId), ]
  df_2 <- df_2[order(df_2$ResponseId), ]
  
  x1 <- mean(df_1$dv)
  x2 <- mean(df_2$dv)
  
  n1 <- length(df_1$gender)/2
  n2 <- length(df_2$gender)/2
  
  s1 <- sd(df_1$dv)
  s2 <- sd(df_2$dv)
  
  s_pooled <- sqrt(
    (
      ((s1*s1)*(n1-1))+((s2*s2)*(n2-1))
    )/
      (n1+n1-2)
  )
  
  d <- (x1-x2)/s_pooled
  
  
  d_paired <- (
    mean(df_1$dv-df_2$dv)/
      sd(df_1$dv-df_2$dv)
  )
  
  d <- d_paired
  
  vd <- ((n1+n2)/(n1*n2))+((d*d)/(2*(n1+n2)))
  
  sed <- sd(df_1$dv-df_2$dv) # sqrt(vd)
  vd <- sed*sed
  
  n <- length(x$gender)/4
  var <- (1/n)+((d_paired*d_paired)/(2*n))
  vd <- var
  sed <- sqrt(vd)
  
  ci_upper <- d+(z*sed)
  ci_lower <- d-(z*sed)
  
  d_paired <- (
    mean(df_1$dv-df_2$dv)/
      sd(df_1$dv-df_2$dv)
  )
  
  
  ci_upper <- d_paired+(z*sed)
  ci_lower <- d_paired-(z*sed)
  
  list(study="Study 1 supp",
       x1=x1
       ,x2=x2
       ,s1=s1
       ,s2=s2
       ,n1=n1
       ,n2=n2
       ,s_pooled=s_pooled
       ,d=d
       ,vd=vd
       ,sed=sed
       ,ci_upper=ci_upper
       ,ci_lower=ci_lower
       ,p=p2
       ,d_paired=d_paired)
     
}

s1_rtot_stats_supp <- s_pooled_fun()
d <- s1_rtot_stats_supp$d

```

In the analyses reported in the main text we included random effects for participant, as well as participant &times; condition random effects (allowing the effect of condition to vary across participants). When we attempted to additionally include random effects for scenario, the model failed to converge. Here we report alternative analyses where we replace the participant &times; condition random effects with random effects for scenario.

First we conducted a linear-mixed-effects model to test if condition influenced MPS-4 responses. Our outcome measure was MPS-4, our predictor variable was condition, and scenario was also included in the model; we allowed intercepts to vary across participants, and across scenarios.

Overall, the model significantly predicted participants responses, and provided a better fit for the data than the baseline model, $\chi$^2^(`r results_anova$Df[2]`) = `r results_anova$Chisq[2]`, *p* `r paste(p_report(p1))`. Condition significantly influenced responses to the MPS-4, *F*(`r aov1$NumDF[1]`, `r aov1$DenDF[1]`) = `r f3`, *p* `r paste(p_report(p3))`; and was a significant predictor in the model when controlling for scenario, $b$ = `r results_coef$Estimate[2]`, *t*(`r results_coef$df[2]`) = `r t1`, *p* `r paste(p_report(p2))`, with the diagnostic descriptions being rated as more immoral than the non-diagnostic descriptions (*d* = `r round(d, digits=2)`).



```{r}
x <- df3
model0 <- lmerTest::lmer(M1 ~ 1
                #   condition
                 + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
          #      , contrasts = list(condition = contr.sum  , valence = contr.sum)
            )

summary(model0)
# model1 <- lmerTest::lmer(R_tot ~
#                   condition*scenario
#                 + (1|ResponseId)
#                 + (1|ResponseId:condition)
#                 , data = x
#                 , contrasts = list(condition = contr.sum  , scenario = contr.sum)
#             )

model1 <- lmerTest::lmer(M1 ~
                  condition*scenario
                + (1|ResponseId)
                # + (1|ResponseId:condition)
                + (1|scenario)
                , data = x
                , contrasts = list(condition = contr.sum  , scenario = contr.sum)
            )

results_anova <- as.data.frame(anova(model0,model1))
results_anova
results_anova$Chisq[2]
results_anova$Df
p1 <- results_anova$`Pr(>Chisq)`[2]
p_report(p1)
#p_report(results_anova$`Pr(>Chisq)`)[2]
results_anova$AIC
summary_model1 <- summary(model1)
summary_model1
summary_model1$varcor
results_coef <- as.data.frame(summary_model1$coefficients)


aov1 <- anova(model1)
f3 <- aov1$`F value`[1]
p3 <- aov1$`Pr(>F)`[1]

results_coef$Estimate[2]
results_coef$`Std. Error`[2]
results_coef$df[2]
t1 <- results_coef$`t value`[2]
p2 <- results_coef$`Pr(>|t|)`[2]

#QuantPsyc::lm.beta(results_coef)
anova(model1)

d <- (mean(x$M1[which(x$condition=="diagnostic")])-mean(x$M1[which(x$condition=="non-diagnostic")]))/sd(x$M1)

tapply(x$R_tot,x$condition,descriptives)

s_pooled <- sqrt(
  (
    ((.9657055^2)*1601)+((.9594647^2)*1601)
  )/
    (1602+1602-2)
)


s_pooled_fun <- function(){
  
  x$dv <- x$M1
  
  z <- 1.959964
  
  df_1 <- x[which(x$condition=="diagnostic"),]
  df_2 <- x[which(x$condition=="non-diagnostic"),]
  
  
  df_1 <- df_1[order(df_1$ResponseId), ]
  df_2 <- df_2[order(df_2$ResponseId), ]
  
  x1 <- mean(df_1$dv)
  x2 <- mean(df_2$dv)
  
  n1 <- length(df_1$gender)/2
  n2 <- length(df_2$gender)/2
  
  s1 <- sd(df_1$dv)
  s2 <- sd(df_2$dv)
  
  s_pooled <- sqrt(
    (
      ((s1*s1)*(n1-1))+((s2*s2)*(n2-1))
    )/
      (n1+n1-2)
  )
  
  d <- (x1-x2)/s_pooled
  
  
  d_paired <- (
    mean(df_1$dv-df_2$dv)/
      sd(df_1$dv-df_2$dv)
  )
  
  d <- d_paired
  
  vd <- ((n1+n2)/(n1*n2))+((d*d)/(2*(n1+n2)))
  
  sed <- sd(df_1$dv-df_2$dv) # sqrt(vd)
  vd <- sed*sed
  
  n <- length(x$gender)/4
  var <- (1/n)+((d_paired*d_paired)/(2*n))
  vd <- var
  sed <- sqrt(vd)
  
  ci_upper <- d+(z*sed)
  ci_lower <- d-(z*sed)
  
  d_paired <- (
    mean(df_1$dv-df_2$dv)/
      sd(df_1$dv-df_2$dv)
  )
  
  
  ci_upper <- d_paired+(z*sed)
  ci_lower <- d_paired-(z*sed)
  
  list(study="Study 1 supp",
       x1=x1
       ,x2=x2
       ,s1=s1
       ,s2=s2
       ,n1=n1
       ,n2=n2
       ,s_pooled=s_pooled
       ,d=d
       ,vd=vd
       ,sed=sed
       ,ci_upper=ci_upper
       ,ci_lower=ci_lower
       ,p=p2
       ,d_paired=d_paired)
     
}

s1_M1_stats_supp <- s_pooled_fun()
d <- s1_M1_stats_supp$d

```


Next we conducted the same linear-mixed-effects model, this time to test if condition influenced MM-1 responses. Our outcome measure was MM-1, our predictor variable was condition, and scenario was also included in the model; we allowed intercepts to vary across participants, and across scenarios.

Overall, the model significantly predicted participants responses, and provided a better fit for the data than the baseline model, $\chi$^2^(`r results_anova$Df[2]`) = `r results_anova$Chisq[2]`, *p* `r paste(p_report(p1))`. Condition significantly influenced responses to the MM-1, *F*(`r aov1$NumDF[1]`, `r aov1$DenDF[1]`) = `r f3`, *p* `r paste(p_report(p3))`; and was a significant predictor in the model when controlling for scenario, $b$ = `r results_coef$Estimate[2]`, *t*(`r results_coef$df[2]`) = `r t1`, *p* `r paste(p_report(p2))`, with the diagnostic descriptions being rated as more immoral than the non-diagnostic descriptions (*d* = `r round(d, digits=2)`).

## Study 1: Differences between the Descriptions

We additionally conducted separate analyses for each scenario individually (for each dependent measure MPS-4, MM-1 and the combined measure). The responses for each scenario across each measure depending on condition are displayed in Figure\ \@ref(fig:S1allscenariosPlot).


```{r}
x <- df3
x$Scenario <- dplyr::recode(x$scenario
              , "francis" = "Francis"
              , "alex" = "Alex"
              , "sam" = "Sam"
              , "robin" = "Robin")

```


```{r S1allscenariosMPS4plot, fig.cap="Study 3: Differences in MPS-4 depending on condition", include=FALSE}


x_error_bars <- Rmisc::summarySE(x, measurevar="R_tot", groupvars=c("condition"
                                                                    , "Scenario"
                                                                    ))
x_error_bars

g <- ggplot(x,
            aes(x = condition, y = R_tot
                , fill=factor(condition
                              ,labels=c("Diagnostic","Non-Diagnostic")
                )
               # , color=factor(Valence)
            )) + 
  
  #scale_y_continuous(limits = c(-0, 140))+
  #, labels = percent_format()
  # )+ 
  ggdist::stat_halfeye(
    adjust = .9, 
    width = .15, 
    .width = 0, 
    justification = -.7, 
    point_colour = NA,
    position = position_dodge(width=0.9)
  ) + 
  geom_boxplot(
    width = .13, 
    outlier.shape = NA
    , position = position_dodge(width=.8)
    , show_guide = FALSE
  ) +
  ## add justified jitter from the {gghalves} package
  gghalves::geom_half_point(
    aes(color=factor(condition
                     #                   ,labels=c("Means","Side-Effect")
    )
    ),
    position = position_dodge(width=4.3),
    ## draw jitter on the left
    side = "l", 
    ## control range of jitter
    range_scale = .4, 
    ## add some transparency
    alpha = .42,
    size = .1,
    show_guide = FALSE
  )+
  # stat_summary(
  #   aes(color=factor(Condition
  #                                         #,labels=c("Gratitude","No Gratitude")
  #   )
  #   ),
  #   geom = "point",
  #   fun = "mean",
  #   col = "black",
  #   size = 1,
  #   shape = 16, #24,
  #   position = position_dodge(width=.2)
  #  # , justification = -.2
  #   , fill = "black"
  #   ,show_guide = FALSE
  # )+
  geom_errorbar(data = x_error_bars,aes(ymin=R_tot-se
                                        , ymax=R_tot+se
                                        , width=.05#, position=pd
                                        # , fill= "black" #factor(condition
                                        #     ,labels=c("Means","Side-Effect")
                                        #)
  )
  , position = position_dodge(width=6.12)
  ) +
  geom_point(data=x_error_bars, inherit.aes = FALSE
             , aes(x=condition, y=R_tot)
             , size=.05
    )+
  #facet_grid(cols = vars(means))+
  xlab("Information Type") +
  ylab("MPS-4") +
  scale_x_discrete(
    labels=c("Diagnostic","Non-Diagnostic")
  ) +
  scale_y_continuous(limits = c(-.0,7)
                     , breaks = seq(0,7, by = 1)  #  c(0:)
                     #                    , labels=c(" ", "1", "2", "3","4","5","6","7")
  ) +
  scale_fill_grey(start = .3, end = .6) +
  scale_color_grey(start = .3, end = .6) +
  guides(
    fill=guide_legend(title = "Information Type")
    , color="none" # guide_legend(title="Valence")
    , shape="none"
  )+
  facet_grid(cols = vars(Scenario)) +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
                                size=12
                                ),
        legend.text=element_text(#family="Times",
                                 size=8
                                 ),
          legend.title=element_text(#family="Times",
                                    size=10
                                    ),
          axis.text=element_text(#family="Times",
                                 colour = "black",
                                 size=8
                                 ),
          axis.ticks.x = element_blank(),
          axis.title=element_text(#family="Times",
                                  size=12
                                  ),
          strip.text=element_text(#family = "Times",
                                  size = 12
                                  ),
         # strip.background = element_rect(fill = "white"),
          legend.position="none")


g
mps4plot <- g

```




```{r S1allscenariosM1plot, fig.cap="Study 3: Differences in MPS-4 depending on condition", include=FALSE}


x_error_bars <- Rmisc::summarySE(x, measurevar="M1", groupvars=c("condition"
                                                                    , "Scenario"
                                                                    ))
x_error_bars

g <- ggplot(x,
            aes(x = condition, y = M1
                , fill=factor(condition
                              ,labels=c("Diagnostic","Non-Diagnostic")
                )
               # , color=factor(Valence)
            )) + 
  
  #scale_y_continuous(limits = c(-0, 140))+
  #, labels = percent_format()
  # )+ 
  ggdist::stat_halfeye(
    adjust = .9, 
    width = .15, 
    .width = 0, 
    justification = -.7, 
    point_colour = NA,
    position = position_dodge(width=0.9)
  ) + 
  geom_boxplot(
    width = .13, 
    outlier.shape = NA
    , position = position_dodge(width=.8)
    , show_guide = FALSE
  ) +
  ## add justified jitter from the {gghalves} package
  gghalves::geom_half_point(
    aes(color=factor(condition
                     #                   ,labels=c("Means","Side-Effect")
    )
    ),
    position = position_dodge(width=4.3),
    ## draw jitter on the left
    side = "l", 
    ## control range of jitter
    range_scale = .4, 
    ## add some transparency
    alpha = .42,
    size = .1,
    show_guide = FALSE
  )+
  # stat_summary(
  #   aes(color=factor(Condition
  #                                         #,labels=c("Gratitude","No Gratitude")
  #   )
  #   ),
  #   geom = "point",
  #   fun = "mean",
  #   col = "black",
  #   size = 1,
  #   shape = 16, #24,
  #   position = position_dodge(width=.2)
  #  # , justification = -.2
  #   , fill = "black"
  #   ,show_guide = FALSE
  # )+
  geom_errorbar(data = x_error_bars,aes(ymin=M1-se
                                        , ymax=M1+se
                                        , width=.05#, position=pd
                                        # , fill= "black" #factor(condition
                                        #     ,labels=c("Means","Side-Effect")
                                        #)
  )
  , position = position_dodge(width=6.12)
  ) +
  geom_point(data=x_error_bars, inherit.aes = FALSE
             , aes(x=condition, y=M1)
             , size=.05
    )+
  #facet_grid(cols = vars(means))+
  xlab("Information Type") +
  ylab("MM-1") +
  scale_x_discrete(
    labels=c("Diagnostic","Non-Diagnostic")
  ) +
  scale_y_continuous(limits = c(-.0,100)
                     , breaks = seq(0,100, by = 10)  #  c(0:)
                     #                    , labels=c(" ", "1", "2", "3","4","5","6","7")
  ) +
  scale_fill_grey(start = .3, end = .6) +
  scale_color_grey(start = .3, end = .6) +
  guides(
    fill=guide_legend(title = "Information Type")
    , color="none" # guide_legend(title="Valence")
    , shape="none"
  )+
  facet_grid(cols = vars(Scenario)) +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
                                size=12
                                ),
        legend.text=element_text(#family="Times",
                                 size=8
                                 ),
          legend.title=element_text(#family="Times",
                                    size=10
                                    ),
          axis.text=element_text(#family="Times",
                                 colour = "black",
                                 size=8
                                 ),
          axis.ticks.x = element_blank(),
          axis.title=element_text(#family="Times",
                                  size=12
                                  ),
          strip.text=element_text(#family = "Times",
                                  size = 12
                                  ),
         # strip.background = element_rect(fill = "white"),
          legend.position="none")


g
M1plot <- g


# M1plot <- 
# ggplot(x,aes(x=condition,y=M1))+
#   geom_violin() +
#   stat_summary(fun=mean, geom="point", shape=23, size=2)+
#   geom_boxplot(width=0.1)+
# #  geom_dotplot(binaxis='y', stackdir='center', dotsize=.05)+
# # violin plot with jittered points
# # 0.2 : degree of jitter in x direction
#   geom_jitter(shape=16
#               , position=position_jitter(0.15)
#               , size=.1
#               , color="dark grey") +
#   xlab("Information Type") +
#   ylab("MM-1") +
#   facet_grid(cols = vars(Scenario)) +
#   theme_bw() +
#   theme(panel.border = element_blank(),
#         axis.line = element_line(size = .2),
#         strip.background  = element_blank(),
#         panel.grid = element_blank(),
#         plot.title=element_text(#family="Times",
#                                 size=12
#                                 ),
#         legend.text=element_text(#family="Times",
#                                  size=8
#                                  ),
#           legend.title=element_text(#family="Times",
#                                     size=10
#                                     ),
#           axis.text=element_text(#family="Times",
#                                  colour = "black",
#                                  size=8
#                                  ),
#           axis.ticks.x = element_blank(),
#           axis.title=element_text(#family="Times",
#                                   size=12
#                                   ),
#           strip.text=element_text(#family = "Times",
#                                   size = 12
#                                   ),
#          # strip.background = element_rect(fill = "white"),
#           legend.position="right")




```



```{r S1allscenariosBothplot, fig.cap="Study 3: Differences in MPS-4 depending on condition", include=FALSE}

# x <- x %>% select(M1R_tot, condition, Scenario)
# install.packages("skimr")
# skimr::skim(x)

#descriptives(x$M1R_tot)
x_error_bars <- Rmisc::summarySE(x, measurevar="M1R_tot", groupvars=c("condition"
                                                                    , "Scenario"
                                                                    ))
x_error_bars

g <- ggplot(x,
            aes(x = condition, y = M1R_tot
                , fill=factor(condition
                              ,labels=c("Diagnostic","Non-Diagnostic")
                )
               # , color=factor(Valence)
            )) + 
  
  #scale_y_continuous(limits = c(-0, 140))+
  #, labels = percent_format()
  # )+ 
  ggdist::stat_halfeye(
    adjust = .9, 
    width = .15, 
    .width = 0, 
    justification = -.7, 
    point_colour = NA,
    position = position_dodge(width=0.9)
  ) + 
  geom_boxplot(
    width = .13, 
    outlier.shape = NA
    , position = position_dodge(width=.8)
    , show_guide = FALSE
  ) +
  ## add justified jitter from the {gghalves} package
  gghalves::geom_half_point(
    aes(color=factor(condition
                     #                   ,labels=c("Means","Side-Effect")
    )
    ),
    position = position_dodge(width=4.3),
    ## draw jitter on the left
    side = "l", 
    ## control range of jitter
    range_scale = .4, 
    ## add some transparency
    alpha = .42,
    size = .1,
    show_guide = FALSE
  )+
  # stat_summary(
  #   aes(color=factor(Condition
  #                                         #,labels=c("Gratitude","No Gratitude")
  #   )
  #   ),
  #   geom = "point",
  #   fun = "mean",
  #   col = "black",
  #   size = 1,
  #   shape = 16, #24,
  #   position = position_dodge(width=.2)
  #  # , justification = -.2
  #   , fill = "black"
  #   ,show_guide = FALSE
  # )+
  geom_errorbar(data = x_error_bars,aes(ymin=M1R_tot-se
                                        , ymax=M1R_tot+se
                                        , width=.05#, position=pd
                                        # , fill= "black" #factor(condition
                                        #     ,labels=c("Means","Side-Effect")
                                        #)
  )
  , position = position_dodge(width=6.12)
  ) +
  geom_point(data=x_error_bars, inherit.aes = FALSE
             , aes(x=condition, y=M1R_tot)
             , size=.05
    )+
  #facet_grid(cols = vars(means))+
  xlab("Information Type") +
  ylab("Combined") +
  scale_x_discrete(
    labels=c("Diagnostic","Non-Diagnostic")
  ) +
  scale_y_continuous(limits = c(-2.5,4)
                     , breaks = seq(-2.5,4, by = .5)  #  c(0:)
                     #                    , labels=c(" ", "1", "2", "3","4","5","6","7")
  ) +
  scale_fill_grey(start = .3, end = .6) +
  scale_color_grey(start = .3, end = .6) +
  guides(
    fill=guide_legend(title = "Information Type")
    , color="none" # guide_legend(title="Valence")
    , shape="none"
  )+
  facet_grid(cols = vars(Scenario)) +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
                                size=12
                                ),
        legend.text=element_text(#family="Times",
                                 size=8
                                 ),
          legend.title=element_text(#family="Times",
                                    size=10
                                    ),
          axis.text=element_text(#family="Times",
                                 colour = "black",
                                 size=8
                                 ),
          axis.ticks.x = element_blank(),
          axis.title=element_text(#family="Times",
                                  size=12
                                  ),
          strip.text=element_text(#family = "Times",
                                  size = 12
                                  ),
         # strip.background = element_rect(fill = "white"),
          legend.position="none")


g
mBothPlot <- g

# mBothPlot <- 
# ggplot(x,aes(x=condition,y=M1R_tot))+
#   geom_violin() +
#   stat_summary(fun=mean, geom="point", shape=23, size=2)+
#   geom_boxplot(width=0.1)+
# #  geom_dotplot(binaxis='y', stackdir='center', dotsize=.05)+
# # violin plot with jittered points
# # 0.2 : degree of jitter in x direction
#   geom_jitter(shape=16
#               , position=position_jitter(0.15)
#               , size=.1
#               , color="dark grey") +
#   xlab("Information Type") +
#   ylab("Combined") +
#   facet_grid(cols = vars(Scenario)) +
#   theme_bw() +
#   theme(panel.border = element_blank(),
#         axis.line = element_line(size = .2),
#         strip.background  = element_blank(),
#         panel.grid = element_blank(),
#         plot.title=element_text(#family="Times",
#                                 size=12
#                                 ),
#         legend.text=element_text(#family="Times",
#                                  size=8
#                                  ),
#           legend.title=element_text(#family="Times",
#                                     size=10
#                                     ),
#           axis.text=element_text(#family="Times",
#                                  colour = "black",
#                                  size=8
#                                  ),
#           axis.ticks.x = element_blank(),
#           axis.title=element_text(#family="Times",
#                                   size=12
#                                   ),
#           strip.text=element_text(#family = "Times",
#                                   size = 12
#                                   ),
#          # strip.background = element_rect(fill = "white"),
#           legend.position="right")




```


```{r}
figure <- ggarrange(mps4plot
                    , M1plot
                    , mBothPlot
                    #,labels = c("A")
                    , ncol = 1
                    , nrow = 3
                    , widths = c(0.485, 0.5))
figure
```


```{r S1allscenariosPlot, fig.cap="Study 1: Differences in moral perception for each description", include=TRUE, fig.height=8, out.width = "\\textwidth", fig.pos = "!h"}

suppressWarnings(print(figure))

```


```{r}

x <- sam
d1 <- lsr::cohensD(R_tot~condition,x)
t1 <- t.test(R_tot~condition,x)
t1$parameter
t1$statistic
t1$p.value

d2 <- lsr::cohensD(M1~condition,x)
t2 <- t.test(M1~condition,x)


d3 <- lsr::cohensD(M1R_tot~condition,x)
t3 <- t.test(M1R_tot~condition,x)

xd <- x[which(x$condition=="diagnostic"),]
xnond <- x[which(x$condition=="non-diagnostic"),]
```

For *Sam*, MPS-4 scores were significantly higher for the non-diagnostic condition (*M* = `r mean(xnond$R_tot)`, *SD* = `r sd(xnond$R_tot)`), than in the diagnostic condition (*M* = `r mean(xd$R_tot)`, *SD* = `r sd(xd$R_tot)`), *t*(`r t1$parameter`) = `r t1$statistic`, *p* `r paste(p_report(t1$p.value))`, *d* = `r d1`; MM-1 ratings were higher in the non-diagnostic condition (*M* = `r mean(xnond$M1)`, *SD* = `r sd(xnond$M1)`), than in the diagnostic condition (*M* = `r mean(xd$M1)`, *SD* = `r sd(xd$M1)`), *t*(`r t2$parameter`) = `r t2$statistic`, *p* `r paste(p_report(t2$p.value))`, *d* = `r d2`. For the combined measure ratings were also higher in the non-diagnostic condition (*M* = `r mean(xnond$M1R_tot)`, *SD* = `r sd(xnond$M1R_tot)`), than in the diagnostic condition (*M* = `r mean(xd$M1R_tot)`, *SD* = `r sd(xd$M1R_tot)`), *t*(`r t3$parameter`) = `r t3$statistic`, *p* `r paste(p_report(t3$p.value))`, *d* = `r d3`.



```{r}

x <- robin
d1 <- lsr::cohensD(R_tot~condition,x)
t1 <- t.test(R_tot~condition,x)
t1$parameter
t1$statistic
t1$p.value

d2 <- lsr::cohensD(M1~condition,x)
t2 <- t.test(M1~condition,x)


d3 <- lsr::cohensD(M1R_tot~condition,x)
t3 <- t.test(M1R_tot~condition,x)

xd <- x[which(x$condition=="diagnostic"),]
xnond <- x[which(x$condition=="non-diagnostic"),]
```

For *Robin*, MPS-4 scores were not significantly different for the non-diagnostic condition (*M* = `r mean(xnond$R_tot)`, *SD* = `r sd(xnond$R_tot)`), than in the diagnostic condition (*M* = `r mean(xd$R_tot)`, *SD* = `r sd(xd$R_tot)`), *t*(`r t1$parameter`) = `r t1$statistic`, *p* `r paste(p_report(t1$p.value))`, *d* = `r d1`; MM-1 ratings were similar in the non-diagnostic condition (*M* = `r mean(xnond$M1)`, *SD* = `r sd(xnond$M1)`), and in the diagnostic condition (*M* = `r mean(xd$M1)`, *SD* = `r sd(xd$M1)`), *t*(`r t2$parameter`) = `r t2$statistic`, *p* `r paste(p_report(t2$p.value))`, *d* = `r d2`. For the combined measure ratings were also similar in the non-diagnostic condition (*M* = `r mean(xnond$M1R_tot)`, *SD* = `r sd(xnond$M1R_tot)`), and in the diagnostic condition (*M* = `r mean(xd$M1R_tot)`, *SD* = `r sd(xd$M1R_tot)`), *t*(`r t3$parameter`) = `r t3$statistic`, *p* `r paste(p_report(t3$p.value))`, *d* = `r d3`.


```{r}

x <- alex
d1 <- lsr::cohensD(R_tot~condition,x)
t1 <- t.test(R_tot~condition,x)
t1$parameter
t1$statistic
t1$p.value

d2 <- lsr::cohensD(M1~condition,x)
t2 <- t.test(M1~condition,x)


d3 <- lsr::cohensD(M1R_tot~condition,x)
t3 <- t.test(M1R_tot~condition,x)

xd <- x[which(x$condition=="diagnostic"),]
xnond <- x[which(x$condition=="non-diagnostic"),]
```

For *Alex*, MPS-4 scores were significantly higher for the non-diagnostic condition (*M* = `r mean(xnond$R_tot)`, *SD* = `r sd(xnond$R_tot)`), than in the diagnostic condition (*M* = `r mean(xd$R_tot)`, *SD* = `r sd(xd$R_tot)`), *t*(`r t1$parameter`) = `r t1$statistic`, *p* `r paste(p_report(t1$p.value))`, *d* = `r d1`; MM-1 ratings were higher in the non-diagnostic condition (*M* = `r mean(xnond$M1)`, *SD* = `r sd(xnond$M1)`), than in the diagnostic condition (*M* = `r mean(xd$M1)`, *SD* = `r sd(xd$M1)`), *t*(`r t2$parameter`) = `r t2$statistic`, *p* `r paste(p_report(t2$p.value))`, *d* = `r d2`. For the combined measure ratings were also higher in the non-diagnostic condition (*M* = `r mean(xnond$M1R_tot)`, *SD* = `r sd(xnond$M1R_tot)`), than in the diagnostic condition (*M* = `r mean(xd$M1R_tot)`, *SD* = `r sd(xd$M1R_tot)`), *t*(`r t3$parameter`) = `r t3$statistic`, *p* `r paste(p_report(t3$p.value))`, *d* = `r d3`.


```{r}

x <- francis
d1 <- lsr::cohensD(R_tot~condition,x)
t1 <- t.test(R_tot~condition,x)
t1$parameter
t1$statistic
t1$p.value

d2 <- lsr::cohensD(M1~condition,x)
t2 <- t.test(M1~condition,x)


d3 <- lsr::cohensD(M1R_tot~condition,x)
t3 <- t.test(M1R_tot~condition,x)

xd <- x[which(x$condition=="diagnostic"),]
xnond <- x[which(x$condition=="non-diagnostic"),]
```

For *Francis*, MPS-4 scores were significantly higher for the non-diagnostic condition (*M* = `r mean(xnond$R_tot)`, *SD* = `r sd(xnond$R_tot)`), than in the diagnostic condition (*M* = `r mean(xd$R_tot)`, *SD* = `r sd(xd$R_tot)`), *t*(`r t1$parameter`) = `r t1$statistic`, *p* `r paste(p_report(t1$p.value))`, *d* = `r d1`; MM-1 ratings were not significantly different in the non-diagnostic condition (*M* = `r mean(xnond$M1)`, *SD* = `r sd(xnond$M1)`), than in the diagnostic condition (*M* = `r mean(xd$M1)`, *SD* = `r sd(xd$M1)`), *t*(`r t2$parameter`) = `r t2$statistic`, *p* `r paste(p_report(t2$p.value))`, *d* = `r d2`. For the combined measure ratings were also similar in the non-diagnostic condition (*M* = `r mean(xnond$M1R_tot)`, *SD* = `r sd(xnond$M1R_tot)`), and in the diagnostic condition (*M* = `r mean(xd$M1R_tot)`, *SD* = `r sd(xd$M1R_tot)`), *t*(`r t3$parameter`) = `r t3$statistic`, *p* `r paste(p_report(t3$p.value))`, *d* = `r d3`.





```{r}
rm(list = ls())
```
