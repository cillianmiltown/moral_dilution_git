---
title             : "Study 3"
shorttitle        : "Moral Dilution"
author:
  - name          : "Blinded"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Blinded"
    email         : "Blinded"
  - name          : "Blinded"
    affiliation   : "2"
  - name          : "Blinded"
    affiliation   : "1"
  - name          : "Blinded"
    affiliation   : "1"
affiliation:
  - id            : "1"
    institution   : "Blinded"
  - id            : "2"
    institution   : "Blinded"
author_note: >
  All procedures performed in studies involving human participants were approved by institutional research ethics committee and conducted in accordance with the Code of Professional Ethics of the Psychological Society of Ireland, and with the 1964 Helsinki declaration and its later amendments or comparable ethical standards. Informed consent was obtained from all individual participants included in the study. The authors declare that there are no potential conflicts of interest with respect to the research, authorship, and/or publication of this article. All authors consented to the submission of this manuscript.
abstract: >
  Six studies etc.
keywords          : "keywords"
wordcount         : "TBC"
bibliography: "../resources/bib/My Library.bib"
csl: "../resources/bib/apa.csl"
figsintext        : true
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
toc               : false
lang              : "en-US"
documentclass     : "apa7"
output:
  papaja::apa6_pdf
header-includes:
- \raggedbottom
editor_options: 
  chunk_output_type: console
---


```{r StudyS2setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include = FALSE)
# knitr::opts_chunk$set(eval = TRUE, echo = TRUE)
#knitr::opts_chunk$set(include = FALSE)
```


```{r StudyS2load_libraries_cogload}
rm(list = ls())
library(citr)
#install.packages("sjstats")
library(plyr)
library(foreign)
library(car)
library(desnum)
library(ggplot2)
library(extrafont)
#devtools::install_github("crsh/papaja")
library(papaja)
#library("dplyr")
library("afex")
library("tibble")
library(scales)
#install.packages("metap")
library(metap)
library(pwr)
library(lsr)
#install.packages("sjstats")
library(sjstats)
library(DescTools)
#inatall.packages("ggstatsplot")
#library(ggstatsplot)
library(VGAM)
library(nnet)
library(mlogit)
library(reshape2)
#install.packages("powerMediation")
library("powerMediation")
library("ggpubr")


# library(rstatix)


#source("load_all_data.R")

#devtools::install_github("benmarwick/wordcountaddin")
#library(wordcountaddin)
#wordcountaddin::text_stats("cogload_1to5_25Sept19.Rmd")
#setwd("manuscript_prep")
getwd()
```



```{r StudyS2LoadData}
#source("~/Dropbox/College/research/Research_general/cog_load/moral_dumbfounding_and_cognitive_load/read_and_sort_raw_data.R")
#source("~/Dropbox/College/research/Research_general/cog_load/moral_dumbfounding_and_cognitive_load/load_study6_data.R")
rm(list = ls())

df3 <- read.csv("../data/study_S2_data_long.csv")
df1 <- read.csv("../data/study_S2_data_wide.csv")
x <- read.csv("../data/study_S2_data_long_clean.csv")

MPS <- x %>% 
  select(R1,R2,R3,R4)

alpha1 <- ltm::cronbach.alpha(MPS)

alpha1
```

# Study S2 - Good and Bad Characters
Study S2 is the same as Study 3, but with an MTurk sample. Study 3 was pre-registered at \color{blue}[https://aspredicted.org/QDF_XT1](https://aspredicted.org/QDF_XT1)\color{black}.


## Study S2: Method
### Study S2: Participants and design
Study S2 was a 2 $\times$ 2 within-subjects factorial design. The first independent variable was condition with two levels, diagnostic and non-diagnostic. The second independent variable was valence of character description, with two levels morally good and morally bad. We used the same two dependent variables as in previous studies, the four item moral perception scale (MPS-4, $\alpha$ = `r round(alpha1$alpha,digits=2)`), and the single item moral perception measure MM-1.

A total sample of `r length(levels(as.factor(df3$ResponseId)))` (`r sum(df1$gender=="2",na.rm=T)` female, `r sum(df1$gender=="1", na.rm=T)` male, `r round(sum(df1$gender=="3", na.rm=T)/1)` non-binary, `r round(sum(df1$gender=="4", na.rm=T))` other; `r sum(df1$gender=="5", na.rm=T)` prefer not to say, *M*~age~ = `r round(mean(df3$age, na.rm=T),digits=2)`, min = `r min(df3$age, na.rm=T)`, max = `r max(df3$age, na.rm=T)`, *SD* = `r round(sd(df3$age, na.rm=T),digits=2)`) started the survey.  Participants were recruited from MTurk and paid $0.40 for their participation.

```{r}
df1 <- read.csv("../data/study_S2_data_long.csv")
df3 <- read.csv("../data/study_S2_data_long_clean.csv")
df_long_clean <- df3
table(df3$gender)
length(df1$gender)/6
length(levels(as.factor(df1$ResponseId)))-length(levels(as.factor(df3$ResponseId)))
length(df3$gender)/4

att_both <- length(levels(as.factor(df1$ResponseId)))-length(levels(as.factor(df3$ResponseId)))
```


```{r}
df_long_clean <- df3

x <- df3
x$attn_chk_1Q
x$attn_chk_2_Q
x <- x[which(x$attn_chk_2_Q==2|x$attn_chk_2_Q==5),]
x <- x[which(x$attn_chk_1Q==7),]
df_long_extra_clean <- x

x <- df3
# 
# df3 <- x
# att_both <- length(levels(as.factor(df1$ResponseId)))-length(levels(as.factor(df3$ResponseId)))


good <- x[which(x$valence=="good"),]
bad <- x[which(x$valence=="bad"),]

good$R_tot_recoded <- 7 - good$R_tot
bad$R_tot_recoded <- bad$R_tot

good$M1_recoded <- 100 - good$M1
bad$M1_recoded <- bad$M1

df_recoded <- rbind(good,bad)


x <- df_long_extra_clean

good <- x[which(x$valence=="good"),]
bad <- x[which(x$valence=="bad"),]

good$R_tot_recoded <- 7 - good$R_tot
bad$R_tot_recoded <- bad$R_tot

good$M1_recoded <- 100 - good$M1
bad$M1_recoded <- bad$M1

df_recoded_extra_clean <- rbind(good,bad)

x <- df_recoded_extra_clean
```

Participants who failed both manipulation checks were removed (*n* = `r att_both`), leaving a total sample of `r length(df3$gender)/4` participants (`r sum(df3$gender=="2",na.rm=T)/4` female, `r sum(df3$gender=="1", na.rm=T)/4` male, `r sum(df3$gender=="4", na.rm=T)/4` other, `r sum(df3$gender=="4", na.rm=T)/4` prefer not to say; *M*~age~ = `r round(mean(df3$age, na.rm=T),digits=2)`, min = `r min(df3$age, na.rm=T)`, max = `r max(df3$age, na.rm=T)`, *SD* = `r round(sd(df3$age, na.rm=T),digits=2)`).


### Study S2: Procedure and materials
Again, data were collected using an online questionnaire presented with Qualtrics (www.qualtrics.com). Participants were presented with four descriptions of characters as in Study 3. To ensure consistency across character judgments, we selected descriptions that related to the same moral foundations (care, fairness, and loyalty). We used the same four character names as in previous studies. The *good* characters were *Sam* and *Robin*, and the *bad* characters were *Francis* and *Alex*, e.g., *Imagine a person named Robin. Throughout their life they have been known to show compassion and empathy for others, act with a sense of fairness and justice, and, never to break their word.* or, *Imagine a person named Alex. Throughout their life they have been known to be cruel, act unfairly, and to betray their own group.* Full descriptions for each character are in the supplementary materials. One description for each the *good* and *bad* characters was randomly assigned to include non-diagnostic information for each participant thus all participants were exposed to all conditions (see \color{blue}[https://osf.io/mdnpv/?view_only=77883e3fbc3d45f1a35fe92d5318cb67](https://osf.io/mdnpv/?view_only=77883e3fbc3d45f1a35fe92d5318cb67)\color{black}  for details of the randomization blocks). Study S2 was pre-registered at \color{blue}[https://aspredicted.org/QDF_XT1](https://aspredicted.org/QDF_XT1)\color{black}


## Study S2: Results


```{r}
x <- df3
sam <- x[which(x$scenario=="sam"),]
francis <- x[which(x$scenario=="francis"),]
alex <- x[which(x$scenario=="alex"),]
robin <- x[which(x$scenario=="robin"),]

```

```{r}
x <- df3
tapply(x$R_tot, x$scenario, descriptives)
# bad <- x[which(x$condition=="diagnostic"),]
# good <- x[which(x$condition=="non-diagnostic"),]
#good$scenario_abb <- droplevels(good$scenario_abb)
x$valence
#x <- bad
aov_full <- rstatix::anova_test(
  data=x
  , dv=R_tot
  , wid = ResponseId
  , within = scenario)
aov1 <- rstatix::get_anova_table(aov_full)
aov1
aov1$DFd

pwc <- x %>%
  rstatix::pairwise_t_test(
    R_tot ~ scenario, paired = TRUE,
    p.adjust.method = "bonferroni"
    )
pwc
p_report(pwc$p[2])

# d1 <- lsr::cohensD(R_tot~condition,x,method="paired")
# t.test(R_tot~condition,x,paired=TRUE)
# t1 <- t.test(x$R_tot~x$scenario,paired=TRUE)
# d1
lapply(pwc$p.adj,p_report)
```




The means and standard deviations for MPS-4 for each scenario are as follows: 
*Sam* (good),
*M*~MPS-4~ = `r mean(sam$R_tot)`, *SD*~MPS-4~ = `r sd(sam$R_tot)`,
*Francis* (bad),
*M*~MPS-4~ = `r mean(francis$R_tot)`, *SD*~MPS-4~ = `r sd(francis$R_tot)`,
*Alex* (bad),
*M*~MPS-4~ = `r mean(alex$R_tot)`, *SD*~MPS-4~ = `r sd(alex$R_tot)`,
*Robin* (good),
*M*~MPS-4~ = `r mean(robin$R_tot)`, *SD*~MPS-4~ = `r sd(robin$R_tot)`. There was significant variation depending on the description, *F*(`r round(aov1$DFn)`,`r round(aov1$DFd)`) = `r aov1$F`, *p* `r paste(p_report(aov1$p))`, partial $\eta$^2^ = `r aov1$ges`. Both the *good* characters (*Robin* and *Sam*) were rated significantly more favorably than both the *bad* characters (*Alex* and *Francis*; all *p*s < .001). There were no differences between *Robin* and *Sam* (*good*: *p* `r paste(p_report(pwc$p[6]))`) or between *Alex* and *Francis* (*bad*; *p* `r paste(p_report(pwc$p[1]))`). 



```{r}
x <- df3
# bad <- x[which(x$condition=="diagnostic"),]
# good <- x[which(x$condition=="non-diagnostic"),]
#good$scenario_abb <- droplevels(good$scenario_abb)

#x <- bad
aov_full <- rstatix::anova_test(
  data=x
  , dv=M1
  , wid = ResponseId
  , within = scenario)
aov1 <- rstatix::get_anova_table(aov_full)
aov1
aov1$DFd

pwc <- x %>%
  rstatix::pairwise_t_test(
    M1 ~ scenario, paired = TRUE,
    p.adjust.method = "bonferroni"
    )
pwc
p_report(pwc$p[2])
lapply(pwc$p.adj, p_report)
paste(pwc$p.adj[2])
pwc$p[2]
# d1 <- lsr::cohensD(M1~condition,x,method="paired")
# t.test(M1~scenario,x,paired=TRUE)
# t1 <- t.test(x$M1~x$scenaro,paired=TRUE)
# d1

```

The means and standard deviations for MM-1 for each scenario are as follows: 
*Sam* (good),
*M*~MM-1~ = `r mean(sam$M1)`, *SD*~MM-1~ = `r sd(sam$M1)`;
*Francis* (bad),
*M*~MM-1~ = `r mean(francis$M1)`, *SD*~MM-1~ = `r sd(francis$M1)`;
*Alex* (bad),
*M*~MM-1~ = `r mean(alex$M1)`, *SD*~MM-1~ = `r sd(alex$M1)`;
*Robin* (good),
*M*~MM-1~ = `r mean(robin$M1)`, *SD*~MM-1~ = `r sd(robin$M1)`. There was significant variation depending on the description, *F*(`r round(aov1$DFn)`,`r round(aov1$DFd)`) = `r aov1$F`, *p* `r paste(p_report(aov1$p))`, partial $\eta$^2^ = `r paste(aov1$ges)`. Again, the *good* characters (*Robin* and *Sam*) were rated significantly more favorably than the *bad* characters (*Alex* and *Francis*; all *p*s < .001). There were no differences between *Robin* and *Sam* (*good*: *p* `r paste(p_report(pwc$p[6]))`) or between *Alex* and *Francis* (*bad*; *p* `r paste(p_report(pwc$p[1]))`). 



```{r}
x <- df3
x <- df_recoded

#x <- df_recoded_extra_clean


model0 <- lmerTest::lmer(R_tot_recoded ~ 1
                #   condition
                 + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
          #      , contrasts = list(condition = contr.sum  , valence = contr.sum)
            )

summary(model0)
model1 <- lmerTest::lmer(R_tot ~
                  condition*scenario
                + (1|ResponseId)
                + (1|ResponseId:condition)
                , data = x
                , contrasts = list(condition = contr.sum  )#, valence = contr.sum)
            )



model1 <- lmerTest::lmer(R_tot_recoded ~
                  condition*valence
                + (1|ResponseId)
                + (1|ResponseId:condition)
                + (1|ResponseId:valence)
                , data = x
                , contrasts = list(condition = contr.sum, valence = contr.sum )#, valence = contr.sum)
            )


summary(model1)
anova(model1)
results_anova <- as.data.frame(anova(model0,model1))
results_anova
results_anova$Chisq[2]
results_anova$Df
p1 <- results_anova$`Pr(>Chisq)`[2]
p_report(p1)
#p_report(results_anova$`Pr(>Chisq)`)[2]
results_anova$AIC
summary_model1 <- summary(model1)
summary_model1
results_coef <- as.data.frame(summary_model1$coefficients)
results_coef

aov1 <- anova(model1)
f3a <- aov1$`F value`[1]
f3b <- aov1$`F value`[2]
f3c <- aov1$`F value`[3]
p3a <- aov1$`Pr(>F)`[1]
p3b <- aov1$`Pr(>F)`[2]
p3c <- aov1$`Pr(>F)`[3]

results_coef$Estimate[2]
results_coef$`Std. Error`[2]
results_coef$df[2]
t1 <- results_coef$`t value`[2]
p2 <- results_coef$`Pr(>|t|)`[2]

#QuantPsyc::lm.beta(results_coef)
anova(model1)
```

We conducted a linear-mixed-effects model to test if our predictors influenced MPS-4 responses. Our outcome measure was MPS-4, our predictor variables were condition and valence; we allowed intercepts and the effects of condition and valence to vary across participants.
Overall, the model significantly predicted participants responses, and provided a better fit for the data than the baseline model,
$\chi$^2^(`r results_anova$Df[2]`) = `r results_anova$Chisq[2]`, *p* `r paste(p_report(p1))`. 
Overall, there was a significant main effect for condition,
*F*(`r aov1$NumDF[1]`, `r round(aov1$DenDF[1])`) = `r f3a`, *p* `r paste(p_report(p3a))`;
valence significantly predicted responses,
*F*(`r aov1$NumDF[2]`, `r round(aov1$DenDF[2])`) = `r f3b`, *p* `r paste(p_report(p3b))`;
and there was no significant condition $\times$ valence interaction,
*F*(`r aov1$NumDF[3]`, `r round(aov1$DenDF[3])`) = `r f3c`, *p* `r paste(p_report(p3c))`.



```{r}
x <- df3
x <- df_recoded
model0 <- lmerTest::lmer(M1 ~ 1
                #   condition
                 + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
          #      , contrasts = list(condition = contr.sum  , valence = contr.sum)
            )

summary(model0)
model1 <- lmerTest::lmer(M1 ~
                  condition*scenario
                + (1|ResponseId)
                + (1|ResponseId:condition)
                , data = x
                , contrasts = list(condition = contr.sum  )#, valence = contr.sum)
            )



model1 <- lmerTest::lmer(M1_recoded ~
                  condition*valence
                + (1|ResponseId)
                + (1|ResponseId:condition)
                + (1|ResponseId:valence)
                , data = x
                , contrasts = list(condition = contr.sum, valence = contr.sum )#, valence = contr.sum)
            )
summary(model1)
anova(model1)
results_anova <- as.data.frame(anova(model0,model1))
results_anova
results_anova$Chisq[2]
results_anova$Df
p1 <- results_anova$`Pr(>Chisq)`[2]
p_report(p1)
#p_report(results_anova$`Pr(>Chisq)`)[2]
results_anova$AIC
summary_model1 <- summary(model1)
summary_model1
results_coef <- as.data.frame(summary_model1$coefficients)
results_coef

aov1 <- anova(model1)
f3a <- aov1$`F value`[1]
f3b <- aov1$`F value`[2]
f3c <- aov1$`F value`[3]
p3a <- aov1$`Pr(>F)`[1]
p3b <- aov1$`Pr(>F)`[2]
p3c <- aov1$`Pr(>F)`[3]

results_coef$Estimate[2]
results_coef$`Std. Error`[2]
results_coef$df[2]
t1 <- results_coef$`t value`[2]
p2 <- results_coef$`Pr(>|t|)`[2]

#QuantPsyc::lm.beta(results_coef)
anova(model1)
```

We conducted a linear-mixed-effects model to test if our predictors influenced MM-1 responses. The model was the same as the previous model, with a change to the outcome measure, our outcome measure for this model was MM-1. As above, our predictor variables were condition and valence; we allowed intercepts and the effects of condition and valence to vary across participants.
Overall, the model significantly predicted participants responses, and provided a better fit for the data than the baseline model,
$\chi$^2^(`r results_anova$Df[2]`) = `r results_anova$Chisq[2]`, *p* `r paste(p_report(p1))`. 
Overall there was a main effect for condition,
*F*(`r aov1$NumDF[1]`, `r round(aov1$DenDF[1])`) = `r f3a`, *p* `r paste(p_report(p3a))`;
valence significantly predicted responses,
*F*(`r aov1$NumDF[2]`, `r round(aov1$DenDF[2])`) = `r f3b`, *p* `r paste(p_report(p3b))`;
and there was no significant condition $\times$ valence interaction,
*F*(`r aov1$NumDF[3]`, `r round(aov1$DenDF[3])`) = `r f3c`, *p* `r paste(p_report(p3c))`.



```{r}
x <- df3
x <- df_recoded


x$M1R_tot_recoded <- scale(scale(x$R_tot_recoded)+scale(x$M1_recoded))
df_recoded_extra_clean <-x



model0 <- lmerTest::lmer(M1R_tot_recoded ~ 1
                #   condition
                 + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
          #      , contrasts = list(condition = contr.sum  , valence = contr.sum)
            )

summary(model0)
model1 <- lmerTest::lmer(M1R_tot_recoded ~
                  condition*scenario
                + (1|ResponseId)
                + (1|ResponseId:condition)
                , data = x
                , contrasts = list(condition = contr.sum  )#, valence = contr.sum)
            )



model1 <- lmerTest::lmer(M1R_tot_recoded ~
                  condition*valence
                + (1|ResponseId)
                + (1|ResponseId:condition)
                + (1|ResponseId:valence)
                , data = x
                , contrasts = list(condition = contr.sum, valence = contr.sum )#, valence = contr.sum)
            )
summary(model1)
anova(model1)
results_anova <- as.data.frame(anova(model0,model1))
results_anova
results_anova$Chisq[2]
results_anova$Df
p1 <- results_anova$`Pr(>Chisq)`[2]
p_report(p1)
#p_report(results_anova$`Pr(>Chisq)`)[2]
results_anova$AIC
summary_model1 <- summary(model1)
summary_model1
results_coef <- as.data.frame(summary_model1$coefficients)
results_coef

aov1 <- anova(model1)
f3a <- aov1$`F value`[1]
f3b <- aov1$`F value`[2]
f3c <- aov1$`F value`[3]
p3a <- aov1$`Pr(>F)`[1]
p3b <- aov1$`Pr(>F)`[2]
p3c <- aov1$`Pr(>F)`[3]

results_coef$Estimate[2]
results_coef$`Std. Error`[2]
results_coef$df[2]
t1 <- results_coef$`t value`[2]
p2 <- results_coef$`Pr(>|t|)`[2]

#QuantPsyc::lm.beta(results_coef)
anova(model1)
```

We conducted a linear-mixed-effects model to test if our predictors influenced responses on the combined moral perception measure. Our outcome measure was the combined moral perception measure, our predictor variables were condition and valence; we allowed intercepts and the effects of condition and valence to vary across participants.
Overall, the model significantly predicted participants responses, and provided a better fit for the data than the baseline model,
$\chi$^2^(`r results_anova$Df[2]`) = `r results_anova$Chisq[2]`, *p* `r paste(p_report(p1))`. 
Condition significantly influenced responses to the combined moral perception measure,
*F*(`r aov1$NumDF[1]`, `r round(aov1$DenDF[1])`) = `r f3a`, *p* `r paste(p_report(p3a))`
and was a significant predictor in the model when controlling for scenario, $b$ = `r results_coef$Estimate[2]`, *t*(`r results_coef$df[2]`) = `r t1`, *p* `r paste(p_report(p2))`;
valence significantly predicted responses,
*F*(`r aov1$NumDF[2]`, `r round(aov1$DenDF[2])`) = `r f3b`, *p* `r paste(p_report(p3b))`;
and there was also a significant condition $\times$ valence interaction,
*F*(`r aov1$NumDF[3]`, `r round(aov1$DenDF[3])`) = `r f3c`, *p* `r paste(p_report(p3c))`, see Figure\ \@ref(fig:S3combinedplot).

For both MP-4 and MM-1 (and the combined measure) we found a main effect for condition and valence, and there was no condition $\times$ valence interaction. We conducted follow-up analyses to test the if the main effect for condition holds for both good and bad descriptions separately.

```{r}
x <- df3

x$Valence <- dplyr::recode(x$valence
              , "good" = "Good"
              , "bad" = "Bad")

```


```{r StudyS2Rtotconditionplot, fig.cap="Study 3: Differences in MPS-4 depending on condition", include=FALSE}


x_error_bars <- Rmisc::summarySE(x, measurevar="R_tot", groupvars=c("condition", "Valence"))
x_error_bars

g <- ggplot(x,
            aes(x = condition, y = R_tot
                , fill=factor(condition
                              ,labels=c("Diagnostic","Non-Diagnostic")
                )
               # , color=factor(Valence)
            )) + 
  
  #scale_y_continuous(limits = c(-0, 140))+
  #, labels = percent_format()
  # )+ 
  ggdist::stat_halfeye(
    adjust = 1, 
    width = .55, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA,
    position = position_dodge(width=0.9)
  ) + 
  geom_boxplot(
    width = .13, 
    outlier.shape = NA
    , position = position_dodge(width=.8)
    , show_guide = FALSE
  ) +
  ## add justified jitter from the {gghalves} package
  gghalves::geom_half_point(
    aes(color=factor(condition
                     #                   ,labels=c("Means","Side-Effect")
    )
    ),
    position = position_dodge(width=4.3),
    ## draw jitter on the left
    side = "l", 
    ## control range of jitter
    range_scale = .4, 
    ## add some transparency
    alpha = .42,
    size = .1,
    show_guide = FALSE
  )+
  stat_summary(
    aes(color=factor(Condition
                                          #,labels=c("Gratitude","No Gratitude")
    )
    ),
    geom = "point",
    fun = "mean",
    col = "black",
    size = 1,
    shape = 16, #24,
    position = position_dodge(width=.2)
   # , justification = -.2
    , fill = "black"
    ,show_guide = FALSE
  )+
  geom_errorbar(data = x_error_bars,aes(ymin=R_tot-se
                                        , ymax=R_tot+se
                                        , width=.05#, position=pd
                                        # , fill= "black" #factor(condition
                                        #     ,labels=c("Means","Side-Effect")
                                        #)
  )
  , position = position_dodge(width=6.12)
  ) +
  #facet_grid(cols = vars(means))+
  xlab("Information Type") +
  ylab("MPS-4")+
  scale_x_discrete(
    labels=c("Diagnostic","Non-Diagnostic")
  ) +
  scale_y_continuous(limits = c(-.0,7)
                     , breaks = seq(0,7, by = 1)  #  c(0:)
                     #                    , labels=c(" ", "1", "2", "3","4","5","6","7")
  ) +
  scale_fill_grey(start = .3, end = .6) +
  scale_color_grey(start = .3, end = .6) +
  guides(
    fill=guide_legend(title = "Information Type")
    , color=guide_legend(title="Valence")
    , shape="none"
  )+
  facet_grid(cols = vars(Valence))+
  #labs(fill="Means/Side-Effect") +
  # 
  # geom_text(#family = "Times",
  #           size=4.2,
  #           aes( label = scales::percent(test$perc),
  #                y= test$perc ),
  #           stat= "identity",
  #           vjust = -.5,
  #           position = position_dodge(.9),
  #           fontface='plain'
  #           )+
#theme_apa() +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        #panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
                                size=12
                                ),
        legend.text=element_text(#family="Times",
                                 size=8
                                 ),
          legend.title=element_text(#family="Times",
                                    size=10
                                    ),
          axis.text=element_text(#family="Times",
                                 colour = "black",
                                 size=8
                                 ),
          axis.ticks.x = element_blank(),
          axis.title=element_text(#family="Times",
                                  size=12
                                  ),
          strip.text=element_text(#family = "Times",
                                  size = 12
                                  ),
         # strip.background = element_rect(fill = "white"),
          legend.position="none")
g
mps4plot <- g

# mps4plot <- 
# ggplot(x,aes(x=condition,y=R_tot))+
#   geom_violin() +
#   stat_summary(fun=mean, geom="point", shape=23, size=2)+
#   geom_boxplot(width=0.1)+
# #  geom_dotplot(binaxis='y', stackdir='center', dotsize=.05)+
# # violin plot with jittered points
# # 0.2 : degree of jitter in x direction
#   geom_jitter(shape=16
#               , position=position_jitter(0.15)
#               , size=.1
#               , color="dark grey") +
#   xlab("Information Type") +
#   ylab("MPS-4") +
#   facet_grid(cols = vars(Valence)) +
#   theme_bw() +
#   theme(panel.border = element_blank(),
#         axis.line = element_line(size = .2),
#         strip.background  = element_blank(),
#         panel.grid = element_blank(),
#         plot.title=element_text(#family="Times",
#                                 size=12
#                                 ),
#         legend.text=element_text(#family="Times",
#                                  size=8
#                                  ),
#           legend.title=element_text(#family="Times",
#                                     size=10
#                                     ),
#           axis.text=element_text(#family="Times",
#                                  colour = "black",
#                                  size=8
#                                  ),
#           axis.ticks.x = element_blank(),
#           axis.title=element_text(#family="Times",
#                                   size=12
#                                   ),
#           strip.text=element_text(#family = "Times",
#                                   size = 12
#                                   ),
#          # strip.background = element_rect(fill = "white"),
#           legend.position="right")




```


```{r StudyS2M1conditionplot, fig.cap="Study 3: Differences in MM1 depending on condition", include=FALSE, out.width = "50%"}


x_error_bars <- Rmisc::summarySE(x, measurevar="M1", groupvars=c("condition", "Valence"))
x_error_bars

g <- ggplot(x,
            aes(x = condition, y = M1
                , fill=factor(condition
                              ,labels=c("Diagnostic","Non-Diagnostic")
                )
               # , color=factor(Valence)
            )) + 
  
  #scale_y_continuous(limits = c(-0, 140))+
  #, labels = percent_format()
  # )+ 
  ggdist::stat_halfeye(
    adjust = 1, 
    width = .55, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA,
    position = position_dodge(width=0.9)
  ) + 
  geom_boxplot(
    width = .13, 
    outlier.shape = NA
    , position = position_dodge(width=.8)
    , show_guide = FALSE
  ) +
  ## add justified jitter from the {gghalves} package
  gghalves::geom_half_point(
    aes(color=factor(condition
                     #                   ,labels=c("Means","Side-Effect")
    )
    ),
    position = position_dodge(width=4.3),
    ## draw jitter on the left
    side = "l", 
    ## control range of jitter
    range_scale = .4, 
    ## add some transparency
    alpha = .42,
    size = .1,
    show_guide = FALSE
  )+
  stat_summary(
    aes(color=factor(Condition
                                          #,labels=c("Gratitude","No Gratitude")
    )
    ),
    geom = "point",
    fun = "mean",
    col = "black",
    size = 1,
    shape = 16, #24,
    position = position_dodge(width=.2)
   # , justification = -.2
    , fill = "black"
    ,show_guide = FALSE
  )+
  geom_errorbar(data = x_error_bars,aes(ymin=M1-se
                                        , ymax=M1+se
                                        , width=.05#, position=pd
                                        # , fill= "black" #factor(condition
                                        #     ,labels=c("Means","Side-Effect")
                                        #)
  )
  , position = position_dodge(width=6.12)
  ) +
  #facet_grid(cols = vars(means))+
  xlab("Information Type") +
  ylab("MM-1")+
  scale_x_discrete(
    labels=c("Diagnostic","Non-Diagnostic")
  ) +
  scale_y_continuous(limits = c(-.0,100)
                     , breaks = seq(0,100, by = 10)  #  c(0:)
                     #                    , labels=c(" ", "1", "2", "3","4","5","6","7")
  ) +
  scale_fill_grey(start = .3, end = .6) +
  scale_color_grey(start = .3, end = .6) +
  guides(
    fill=guide_legend(title = "Information Type")
    , color=guide_legend(title="Valence")
    , shape="none"
  )+
  facet_grid(cols = vars(Valence))+
  #labs(fill="Means/Side-Effect") +
  # 
  # geom_text(#family = "Times",
  #           size=4.2,
  #           aes( label = scales::percent(test$perc),
  #                y= test$perc ),
  #           stat= "identity",
  #           vjust = -.5,
  #           position = position_dodge(.9),
  #           fontface='plain'
  #           )+
#theme_apa() +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        #panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
                                size=12
                                ),
        legend.text=element_text(#family="Times",
                                 size=8
                                 ),
          legend.title=element_text(#family="Times",
                                    size=10
                                    ),
          axis.text=element_text(#family="Times",
                                 colour = "black",
                                 size=8
                                 ),
          axis.ticks.x = element_blank(),
          axis.title=element_text(#family="Times",
                                  size=12
                                  ),
          strip.text=element_text(#family = "Times",
                                  size = 12
                                  ),
         # strip.background = element_rect(fill = "white"),
          legend.position="none")

g

M1plot <- g

# M1plot <- 
#   ggplot(x,aes(x=condition,y=M1))+
#   geom_violin() +
#   stat_summary(fun=mean, geom="point", shape=23, size=2)+
#   geom_boxplot(width=0.1)+
#   #  geom_dotplot(binaxis='y', stackdir='center', dotsize=.05)+
#   # violin plot with jittered points
#   # 0.2 : degree of jitter in x direction
#   geom_jitter(shape=16
#               , position=position_jitter(0.15)
#               , size=.1
#               , color="dark grey") +
#   xlab("Information Type") +
#   ylab("MM-1")+
#   facet_grid(cols = vars(Valence)) +
#   theme_bw() +
#   theme(panel.border = element_blank(),
#         axis.line = element_line(size = .2),
#         strip.background  = element_blank(),
#         panel.grid = element_blank(),
#         plot.title=element_text(#family="Times",
#           size=12
#         ),
#         legend.text=element_text(#family="Times",
#           size=8
#         ),
#         legend.title=element_text(#family="Times",
#           size=10
#         ),
#         axis.text=element_text(#family="Times",
#           colour = "black",
#           size=8
#         ),
#         axis.ticks.x = element_blank(),
#         axis.title=element_text(#family="Times",
#           size=12
#         ),
#         strip.text=element_text(#family = "Times",
#           size = 12
#         ),
#         # strip.background = element_rect(fill = "white"),
#         legend.position="right")




```


```{r}


x_error_bars <- Rmisc::summarySE(x, measurevar="M1R_tot", groupvars=c("condition", "Valence"))
x_error_bars

g <- ggplot(x,
            aes(x = condition, y = M1R_tot
                , fill=factor(condition
                              ,labels=c("Diagnostic","Non-Diagnostic")
                )
               # , color=factor(Valence)
            )) + 
  
  #scale_y_continuous(limits = c(-0, 140))+
  #, labels = percent_format()
  # )+ 
  ggdist::stat_halfeye(
    adjust = 1, 
    width = .55, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA,
    position = position_dodge(width=0.9)
  ) + 
  geom_boxplot(
    width = .13, 
    outlier.shape = NA
    , position = position_dodge(width=.8)
    , show_guide = FALSE
  ) +
  ## add justified jitter from the {gghalves} package
  gghalves::geom_half_point(
    aes(color=factor(condition
                     #                   ,labels=c("Means","Side-Effect")
    )
    ),
    position = position_dodge(width=4.3),
    ## draw jitter on the left
    side = "l", 
    ## control range of jitter
    range_scale = .4, 
    ## add some transparency
    alpha = .42,
    size = .1,
    show_guide = FALSE
  )+
  geom_point(data=x_error_bars, inherit.aes = FALSE
             , aes(x=condition, y=M1R_tot)
             , size=.5
    )+
  # stat_summary(
  #   aes(color=factor(Condition
  #                                         #,labels=c("Gratitude","No Gratitude")
  #   )
  #   ),
  #   geom = "point",
  #   fun = "mean",
  #   col = "black",
  #   size = 1,
  #   shape = 16, #24,
  #   position = position_dodge(width=.2)
  #  # , justification = -.2
  #   , fill = "black"
  #   ,show_guide = FALSE
  # )+
  geom_errorbar(data = x_error_bars,aes(ymin=M1R_tot-se
                                        , ymax=M1R_tot+se
                                        , width=.05#, position=pd
                                        # , fill= "black" #factor(condition
                                        #     ,labels=c("Means","Side-Effect")
                                        #)
  )
  , position = position_dodge(width=6.12)
  ) +
  #facet_grid(cols = vars(means))+
  xlab("Information Type") +
  ylab("Combined")+
  scale_x_discrete(
    labels=c("Diagnostic","Non-Diagnostic")
  ) +
  scale_y_continuous(limits = c(-2.5,1.2)
                     , breaks = seq(-2.5,1.2, by = .5)  #  c(0:)
                     #                    , labels=c(" ", "1", "2", "3","4","5","6","7")
  ) +
  scale_fill_grey(start = .3, end = .6) +
  scale_color_grey(start = .3, end = .6) +
  guides(
    fill=guide_legend(title = "Information Type")
    , color=guide_legend(title="Valence")
    , shape="none"
  )+
  facet_grid(cols = vars(Valence))+
  #labs(fill="Means/Side-Effect") +
  # 
  # geom_text(#family = "Times",
  #           size=4.2,
  #           aes( label = scales::percent(test$perc),
  #                y= test$perc ),
  #           stat= "identity",
  #           vjust = -.5,
  #           position = position_dodge(.9),
  #           fontface='plain'
  #           )+
#theme_apa() +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        #panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
                                size=12
                                ),
        legend.text=element_text(#family="Times",
                                 size=8
                                 ),
          legend.title=element_text(#family="Times",
                                    size=10
                                    ),
          axis.text=element_text(#family="Times",
                                 colour = "black",
                                 size=8
                                 ),
          axis.ticks.x = element_blank(),
          axis.title=element_text(#family="Times",
                                  size=12
                                  ),
          strip.text=element_text(#family = "Times",
                                  size = 12
                                  ),
         # strip.background = element_rect(fill = "white"),
          legend.position="none")
g
mBothPlot <- g

```


```{r}
figure <- ggarrange(mps4plot
                    , M1plot
                    , mBothPlot
                    #,labels = c("A")
                    , ncol = 1
                    , nrow = 3
                    #, widths = c(0.485, 0.5)
                    )
figure
```


```{r StudyS2bothconditionplot, fig.cap="Study S2: Differences in moral perception depending on condition", include=TRUE, fig.height=8, out.width = "\\textwidth", fig.pos = "!h"}

suppressWarnings(print(figure))

```



## Differences in the *Bad* Descriptions


```{r}
x <- df3

#x <- df_long_extra_clean

x <- x[which(x$valence=="bad"),]


model0 <- lmerTest::lmer(R_tot ~ 1
                #   condition
                 + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
                #, contrasts = list(condition = contr.sum  , valence = contr.sum)
            )

summary(model0)
model1 <- lmerTest::lmer(R_tot ~
                  condition*scenario
                + (1|ResponseId)
             #   + (1|ResponseId:condition)
                , data = x
                , contrasts = list(condition = contr.sum  , scenario = contr.sum)
            )
anova(model1)
summary(model1)


model1_std <- lmerTest::lmer(scale(R_tot, scale = TRUE) ~
                  condition*scenario
                + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
                , contrasts = list(condition = contr.sum  , scenario = contr.sum)
            )
summary(model1_std)
b_std <- as.data.frame(summary(model1_std)$coefficients)$Estimate[2]

results_anova <- as.data.frame(anova(model0,model1))
results_anova
results_anova$Chisq[2]
results_anova$Df
p1 <- results_anova$`Pr(>Chisq)`[2]
p_report(p1)
#p_report(results_anova$`Pr(>Chisq)`)[2]
results_anova$AIC
summary_model1 <- summary(model1)


results_coef <- as.data.frame(summary_model1$coefficients)

aov1 <- anova(model1)
f3 <- aov1$`F value`[1]
p3 <- aov1$`Pr(>F)`[1]


results_coef$Estimate[2]
results_coef$`Std. Error`[2]
results_coef$df[2]
results_coef$`t value`[2]
t1 <- results_coef$`t value`[2]

p2 <- results_coef$`Pr(>|t|)`[2]

#QuantPsyc::lm.beta(results_coef)
anova(model1)


s_pooled_fun <- function(){
  
  x$dv <- x$R_tot
  
  z <- 1.959964
  
  df_1 <- x[which(x$condition=="diagnostic"),]
  df_2 <- x[which(x$condition=="non-diagnostic"),]
  
  
  df_1 <- df_1[order(df_1$ResponseId), ]
  df_2 <- df_2[order(df_2$ResponseId), ]
  
  x1 <- mean(df_1$dv)
  x2 <- mean(df_2$dv)
  
  n1 <- length(df_1$gender)
  n2 <- length(df_2$gender)
  
  s1 <- sd(df_1$dv)
  s2 <- sd(df_2$dv)
  
  s_pooled <- sqrt(
    (
      ((s1*s1)*(n1-1))+((s2*s2)*(n2-1))
    )/
      (n1+n1-2)
  )
  
  d <- (x1-x2)/s_pooled
  
  
  d_paired <- (
    mean(df_1$dv-df_2$dv)/
      sd(df_1$dv-df_2$dv)
  )
  
  d <- d_paired
  
  vd <- ((n1+n2)/(n1*n2))+((d*d)/(2*(n1+n2)))
  
  sed <- sqrt(vd)
  
  ci_upper <- d+(z*sed)
  ci_lower <- d-(z*sed)
  
  d_paired <- (
    mean(df_1$dv-df_2$dv)/
      sd(df_1$dv-df_2$dv)
  )
  
  
  n <- length(x$gender)/4
  var <- (1/n)+((d_paired*d_paired)/(2*n))
  vd <- var
  sed <- sqrt(vd)
  
  
  ci_upper <- d_paired+(z*sed)
  ci_lower <- d_paired-(z*sed)
  
  list(study="Study S2",
       x1=x1
       ,x2=x2
       ,s1=s1
       ,s2=s2
       ,n1=n1
       ,n2=n2
       ,s_pooled=s_pooled
       ,d=d
       ,vd=vd
       ,sed=sed
       ,ci_upper=ci_upper
       ,ci_lower=ci_lower
       ,p=p2
       ,d_paired=d_paired)
     
}

supp_s2bad_rtot_stats <- s_pooled_fun()
d <- supp_s2bad_rtot_stats$d

```



```{r}

y <- supp_s2bad_rtot_stats

icc <- performance::icc(model1)
icc$ICC_unadjusted

names_for_table <- c("b", "SE", "df", "t", "p"
  , "Mdiag", "SDdiag", "Mnond", "SDnond"
  , "d", "upper","lower","variance","ICC")

results_coef_for_table <- results_coef[2,]
class(results_coef_for_table)

supp_s2bad_rtot_for_table <- 
  `colnames<-`(
    cbind.data.frame(results_coef_for_table
                     , y$x1, y$s1, y$x2, y$s2
                     , y$d_paired, y$ci_upper, y$ci_lower
                     , y$vd, icc$ICC_unadjusted)
    ,names_for_table)

rm(y)


supp_s2bad_rtot_vars <- as.data.frame(VarCorr(model1))

```

For the *bad* characters, we conducted a linear-mixed-effects model to test if condition influenced MPS-4 responses. Our outcome measure was MPS-4, our predictor variable was condition; we allowed intercepts and the effect of condition to vary across participants. Overall, the model did not significantly predict participants responses, or provide a better fit for the data than the baseline model, $\chi$^2^(`r results_anova$Df[2]`) = `r results_anova$Chisq[2]`, *p* `r paste(p_report(p1))`. Condition did not significantly influence MPS-4 responses *F*(`r aov1$NumDF[1]`, `r aov1$DenDF[1]`) = `r f3`, *p* `r paste(p_report(p3))`, and was not a significant predictor in the model $b$ = `r results_coef$Estimate[2]` ($\beta$ = `r b_std`), *t*(`r results_coef$df[2]`) = `r t1`, *p* `r paste(p_report(p2))`, (*d* = `r round(d, digits=2)`), see Figure\ \@ref(fig:StudyS2bothconditionplot).





```{r}
x <- df3
df4 <- df_long_extra_clean
x <- df_long_extra_clean

x <- x[which(x$valence=="bad"),]


model0 <- lmerTest::lmer(R_tot ~ 1
                #   condition
                 + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
                #, contrasts = list(condition = contr.sum  , valence = contr.sum)
            )

summary(model0)
model1 <- lmerTest::lmer(R_tot ~
                  condition*scenario
                + (1|ResponseId)
             #   + (1|ResponseId:condition)
                , data = x
                , contrasts = list(condition = contr.sum  , scenario = contr.sum)
            )
anova(model1)
summary(model1)



model1_std <- lmerTest::lmer(scale(M1, scale = TRUE) ~
                  condition*scenario
                + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
                , contrasts = list(condition = contr.sum  , scenario = contr.sum)
            )
summary(model1_std)
b_std <- as.data.frame(summary(model1_std)$coefficients)$Estimate[2]


results_anova <- as.data.frame(anova(model0,model1))
results_anova
results_anova$Chisq[2]
results_anova$Df
p1 <- results_anova$`Pr(>Chisq)`[2]
p_report(p1)
#p_report(results_anova$`Pr(>Chisq)`)[2]
results_anova$AIC
summary_model1 <- summary(model1)


results_coef <- as.data.frame(summary_model1$coefficients)

aov1 <- anova(model1)
f3 <- aov1$`F value`[1]
p3 <- aov1$`Pr(>F)`[1]


results_coef$Estimate[2]
results_coef$`Std. Error`[2]
results_coef$df[2]
results_coef$`t value`[2]
t1 <- results_coef$`t value`[2]

p2 <- results_coef$`Pr(>|t|)`[2]

#QuantPsyc::lm.beta(results_coef)
anova(model1)



```

```{r include=FALSE}

# There was a high degree of variability in the responses to the bad descriptions, with multiple participants rating the characters as good characters. It is possible that this reflects inattentive participants. Thus, as a follow-up exploratory analysis we employed a stricter measure of attention, and excluded participants who failed either attention check question. This left a sample of `r length(df4$gender)/4` participants (`r sum(df4$gender=="1",na.rm=T)/4` female, `r sum(df4$gender=="2", na.rm=T)/4` male, `r sum(df4$gender=="4", na.rm=T)/4` other, `r sum(df4$gender=="4", na.rm=T)/4` prefer not to say; *M*~age~ = `r round(mean(df4$age, na.rm=T),digits=2)`, min = `r min(df4$age, na.rm=T)`, max = `r max(df4$age, na.rm=T)`, *SD* = `r round(sd(df4$age, na.rm=T),digits=2)`). Using this stricter attention measure we conducted an additional linear-mixed-effects model to test if condition influenced MPS-4 responses. Overall, the model did not significantly predict participants responses, or provide a better fit for the data than the baseline model, $\chi$^2^(`r results_anova$Df[2]`) = `r results_anova$Chisq[2]`, *p* `r paste(p_report(p1))`. Condition did not significantly influence MPS-4 responses *F*(`r aov1$NumDF[1]`, `r aov1$DenDF[1]`) = `r f3`, *p* `r paste(p_report(p3))`, and was not a significant predictor in the model $b$ = `r results_coef$Estimate[2]`, *t*(`r results_coef$df[2]`) = `r t1`, *p* `r paste(p_report(p2))`.

```




```{r}
x <- df3

x <- x[which(x$valence=="bad"),]


model0 <- lmerTest::lmer(M1 ~ 1
                #   condition
                 + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
                #, contrasts = list(condition = contr.sum  , valence = contr.sum)
            )

summary(model0)
model1 <- lmerTest::lmer(M1 ~
                  condition*scenario
                + (1|ResponseId)
             #   + (1|ResponseId:condition)
                , data = x
                , contrasts = list(condition = contr.sum  , scenario = contr.sum)
            )
anova(model1)
summary(model1)
results_anova <- as.data.frame(anova(model0,model1))
results_anova
results_anova$Chisq[2]
results_anova$Df
p1 <- results_anova$`Pr(>Chisq)`[2]
p_report(p1)
#p_report(results_anova$`Pr(>Chisq)`)[2]
results_anova$AIC
summary_model1 <- summary(model1)


results_coef <- as.data.frame(summary_model1$coefficients)

aov1 <- anova(model1)
f3 <- aov1$`F value`[1]
p3 <- aov1$`Pr(>F)`[1]


results_coef$Estimate[2]
results_coef$`Std. Error`[2]
results_coef$df[2]
results_coef$`t value`[2]
t1 <- results_coef$`t value`[2]

p2 <- results_coef$`Pr(>|t|)`[2]

#QuantPsyc::lm.beta(results_coef)
anova(model1)


s_pooled_fun <- function(){
  
  x$dv <- x$M1
  
  
  z <- 1.959964
  
  df_1 <- x[which(x$condition=="diagnostic"),]
  df_2 <- x[which(x$condition=="non-diagnostic"),]
  
  
  df_1 <- df_1[order(df_1$ResponseId), ]
  df_2 <- df_2[order(df_2$ResponseId), ]
  
  x1 <- mean(df_1$dv)
  x2 <- mean(df_2$dv)
  
  n1 <- length(df_1$gender)
  n2 <- length(df_2$gender)
  
  s1 <- sd(df_1$dv)
  s2 <- sd(df_2$dv)
  
  s_pooled <- sqrt(
    (
      ((s1*s1)*(n1-1))+((s2*s2)*(n2-1))
    )/
      (n1+n1-2)
  )
  
  d <- (x1-x2)/s_pooled
  
  
  d_paired <- (
    mean(df_1$dv-df_2$dv)/
      sd(df_1$dv-df_2$dv)
  )
  
  d <- d_paired
  
  vd <- ((n1+n2)/(n1*n2))+((d*d)/(2*(n1+n2)))
  
  sed <- sqrt(vd)
  
  ci_upper <- d+(z*sed)
  ci_lower <- d-(z*sed)
  
  d_paired <- (
    mean(df_1$dv-df_2$dv)/
      sd(df_1$dv-df_2$dv)
  )
  
  
  n <- length(x$gender)/4
  var <- (1/n)+((d_paired*d_paired)/(2*n))
  vd <- var
  sed <- sqrt(vd)
  
  
  ci_upper <- d_paired+(z*sed)
  ci_lower <- d_paired-(z*sed)
  
  list(study="Study S2",
       x1=x1
       ,x2=x2
       ,s1=s1
       ,s2=s2
       ,n1=n1
       ,n2=n2
       ,s_pooled=s_pooled
       ,d=d
       ,vd=vd
       ,sed=sed
       ,ci_upper=ci_upper
       ,ci_lower=ci_lower
       ,p=p2
       ,d_paired=d_paired)
     
}

supp_s2bad_M1_stats <- s_pooled_fun()
d <- supp_s2bad_M1_stats$d
d



```


```{r}

y <- supp_s2bad_M1_stats

icc <- performance::icc(model1)
icc$ICC_unadjusted

names_for_table <- c("b", "SE", "df", "t", "p"
  , "Mdiag", "SDdiag", "Mnond", "SDnond"
  , "d", "upper","lower","variance","ICC")

results_coef_for_table <- results_coef[2,]
class(results_coef_for_table)

supp_s2bad_M1_for_table <- 
  `colnames<-`(
    cbind.data.frame(results_coef_for_table
                     , y$x1, y$s1, y$x2, y$s2
                     , y$d_paired, y$ci_upper, y$ci_lower
                     , y$vd, icc$ICC_unadjusted)
    ,names_for_table)

rm(y)

supp_s2bad_M1_vars <- as.data.frame(VarCorr(model1))



save(supp_s2bad_rtot_for_table, supp_s2bad_M1_for_table, supp_s2bad_rtot_vars, supp_s2bad_M1_vars,  file = "supp_s2bad_table_data.RData")


```

We also conducted a linear-mixed-effects model to test if condition influenced MM-1 responses. Our outcome measure was MM-1, our predictor variable was condition; we allowed intercepts and the effect of condition to vary across participants. Overall, the model significantly predicted participants responses, and provided a better fit for the data than the baseline model, $\chi$^2^(`r results_anova$Df[2]`) = `r results_anova$Chisq[2]`, *p* `r paste(p_report(p1))`. Condition significantly influenced MM-1 responses *F*(`r aov1$NumDF[1]`, `r aov1$DenDF[1]`) = `r f3`, *p* `r paste(p_report(p3))`, and was a significant predictor in the model $b$ = `r results_coef$Estimate[2]` ($\beta$ = `r b_std`), *t*(`r results_coef$df[2]`) = `r t1`, *p* `r paste(p_report(p2))`, (*d* = `r round(d, digits=2)`), see Figure\ \@ref(fig:StudyS2bothconditionplot).



## Differences in the *Good* Descriptions


```{r}
x <- df3

x <- x[which(x$valence=="good"),]


model0 <- lmerTest::lmer(R_tot ~ 1
                #   condition
                 + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
                #, contrasts = list(condition = contr.sum  , valence = contr.sum)
            )

summary(model0)
model1 <- lmerTest::lmer(R_tot ~
                  condition*scenario
                + (1|ResponseId)
             #   + (1|ResponseId:condition)
                , data = x
                , contrasts = list(condition = contr.sum  , scenario = contr.sum)
            )
anova(model1)
summary(model1)

model1_std <- lmerTest::lmer(scale(R_tot, scale = TRUE) ~
                  condition*scenario
                + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
                , contrasts = list(condition = contr.sum  , scenario = contr.sum)
            )
summary(model1_std)
b_std <- as.data.frame(summary(model1_std)$coefficients)$Estimate[2]



results_anova <- as.data.frame(anova(model0,model1))
results_anova
results_anova$Chisq[2]
results_anova$Df
p1 <- results_anova$`Pr(>Chisq)`[2]
p_report(p1)
#p_report(results_anova$`Pr(>Chisq)`)[2]
results_anova$AIC
summary_model1 <- summary(model1)


results_coef <- as.data.frame(summary_model1$coefficients)

aov1 <- anova(model1)
f3 <- aov1$`F value`[1]
p3 <- aov1$`Pr(>F)`[1]


results_coef$Estimate[2]
results_coef$`Std. Error`[2]
results_coef$df[2]
results_coef$`t value`[2]
t1 <- results_coef$`t value`[2]

p2 <- results_coef$`Pr(>|t|)`[2]

#QuantPsyc::lm.beta(results_coef)
anova(model1)




s_pooled_fun <- function(){
  
  x$dv <- x$R_tot
  
  
  z <- 1.959964
  
  df_1 <- x[which(x$condition=="diagnostic"),]
  df_2 <- x[which(x$condition=="non-diagnostic"),]
  
  
  df_1 <- df_1[order(df_1$ResponseId), ]
  df_2 <- df_2[order(df_2$ResponseId), ]
  
  x1 <- mean(df_1$dv)
  x2 <- mean(df_2$dv)
  
  n1 <- length(df_1$gender)
  n2 <- length(df_2$gender)
  
  s1 <- sd(df_1$dv)
  s2 <- sd(df_2$dv)
  
  s_pooled <- sqrt(
    (
      ((s1*s1)*(n1-1))+((s2*s2)*(n2-1))
    )/
      (n1+n1-2)
  )
  
  d <- (x1-x2)/s_pooled
  
  
  d_paired <- (
    mean(df_1$dv-df_2$dv)/
      sd(df_1$dv-df_2$dv)
  )
  
  d <- d_paired
  
  vd <- ((n1+n2)/(n1*n2))+((d*d)/(2*(n1+n2)))
  
  sed <- sqrt(vd)
  
  ci_upper <- d+(z*sed)
  ci_lower <- d-(z*sed)
  
  d_paired <- (
    mean(df_1$dv-df_2$dv)/
      sd(df_1$dv-df_2$dv)
  )
  
  
  n <- length(x$gender)/4
  var <- (1/n)+((d_paired*d_paired)/(2*n))
  vd <- var
  sed <- sqrt(vd)
  
  
  ci_upper <- d_paired+(z*sed)
  ci_lower <- d_paired-(z*sed)
  
  list(study="Study S2",
       x1=x1
       ,x2=x2
       ,s1=s1
       ,s2=s2
       ,n1=n1
       ,n2=n2
       ,s_pooled=s_pooled
       ,d=d
       ,vd=vd
       ,sed=sed
       ,ci_upper=ci_upper
       ,ci_lower=ci_lower
       ,p=p2
       ,d_paired=d_paired)
     
}

supp_s2good_rtot_stats <- s_pooled_fun()
d <- supp_s2good_rtot_stats$d

```


```{r}

y <- supp_s2good_rtot_stats

icc <- performance::icc(model1)
icc$ICC_unadjusted

names_for_table <- c("b", "SE", "df", "t", "p"
  , "Mdiag", "SDdiag", "Mnond", "SDnond"
  , "d", "upper","lower","variance","ICC")

results_coef_for_table <- results_coef[2,]
class(results_coef_for_table)

supp_s2good_rtot_for_table <- 
  `colnames<-`(
    cbind.data.frame(results_coef_for_table
                     , y$x1, y$s1, y$x2, y$s2
                     , y$d_paired, y$ci_upper, y$ci_lower
                     , y$vd, icc$ICC_unadjusted)
    ,names_for_table)

rm(y)

supp_s2good_rtot_vars <- as.data.frame(VarCorr(model1))

```

For the *good* characters, we conducted a linear-mixed-effects model to test if condition influenced MPS-4 responses. Our outcome measure was MPS-4, our predictor variable was condition; we allowed intercepts and the effect of condition to vary across participants. Overall, the model significantly predicted participants responses, and provided a better fit for the data than the baseline model, $\chi$^2^(`r results_anova$Df[2]`) = `r results_anova$Chisq[2]`, *p* `r paste(p_report(p1))`. Condition significantly influenced MPS-4 responses *F*(`r aov1$NumDF[1]`, `r aov1$DenDF[1]`) = `r f3`, *p* `r paste(p_report(p3))`, and was a significant predictor in the model $b$ = `r results_coef$Estimate[2]` ($\beta$ = `r b_std`), *t*(`r results_coef$df[2]`) = `r t1`, *p* `r paste(p_report(p2))`, (*d* = `r round(d, digits=2)`), see Figure\ \@ref(fig:StudyS2bothconditionplot).




```{r}
x <- df3

x <- x[which(x$valence=="good"),]


model0 <- lmerTest::lmer(M1 ~ 1
                #   condition
                 + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
                #, contrasts = list(condition = contr.sum  , valence = contr.sum)
            )

summary(model0)
model1 <- lmerTest::lmer(M1 ~
                  condition#*scenario
                + (1|ResponseId)
             #   + (1|ResponseId:condition)
                , data = x
                , contrasts = list(condition = contr.sum  , scenario = contr.sum)
            )
anova(model1)
summary(model1)




model1_std <- lmerTest::lmer(scale(M1, scale = TRUE) ~
                  condition*scenario
                + (1|ResponseId)
                # + (1|ResponseId:condition)
                , data = x
                , contrasts = list(condition = contr.sum  , scenario = contr.sum)
            )
summary(model1_std)
b_std <- as.data.frame(summary(model1_std)$coefficients)$Estimate[2]





results_anova <- as.data.frame(anova(model0,model1))
results_anova
results_anova$Chisq[2]
results_anova$Df
p1 <- results_anova$`Pr(>Chisq)`[2]
p_report(p1)
#p_report(results_anova$`Pr(>Chisq)`)[2]
results_anova$AIC
summary_model1 <- summary(model1)


results_coef <- as.data.frame(summary_model1$coefficients)

aov1 <- anova(model1)
f3 <- aov1$`F value`[1]
p3 <- aov1$`Pr(>F)`[1]


results_coef$Estimate[2]
results_coef$`Std. Error`[2]
round(results_coef$df[2])
results_coef$`t value`[2]
t1 <- results_coef$`t value`[2]

p2 <- results_coef$`Pr(>|t|)`[2]

#QuantPsyc::lm.beta(results_coef)
anova(model1)


s_pooled_fun <- function(){
  
  x$dv <- x$M1
  
 
  z <- 1.959964
  
  df_1 <- x[which(x$condition=="diagnostic"),]
  df_2 <- x[which(x$condition=="non-diagnostic"),]
  
  
  df_1 <- df_1[order(df_1$ResponseId), ]
  df_2 <- df_2[order(df_2$ResponseId), ]
  
  x1 <- mean(df_1$dv)
  x2 <- mean(df_2$dv)
  
  n1 <- length(df_1$gender)
  n2 <- length(df_2$gender)
  
  s1 <- sd(df_1$dv)
  s2 <- sd(df_2$dv)
  
  s_pooled <- sqrt(
    (
      ((s1*s1)*(n1-1))+((s2*s2)*(n2-1))
    )/
      (n1+n1-2)
  )
  
  d <- (x1-x2)/s_pooled
  
  
  d_paired <- (
    mean(df_1$dv-df_2$dv)/
      sd(df_1$dv-df_2$dv)
  )
  
  d <- d_paired
  
  vd <- ((n1+n2)/(n1*n2))+((d*d)/(2*(n1+n2)))
  
  sed <- sqrt(vd)
  
  ci_upper <- d+(z*sed)
  ci_lower <- d-(z*sed)
  
  d_paired <- (
    mean(df_1$dv-df_2$dv)/
      sd(df_1$dv-df_2$dv)
  )
  
  
  n <- length(x$gender)/4
  var <- (1/n)+((d_paired*d_paired)/(2*n))
  vd <- var
  sed <- sqrt(vd)
  
  
  ci_upper <- d_paired+(z*sed)
  ci_lower <- d_paired-(z*sed)
  
  list(study="Study S2",
       x1=x1
       ,x2=x2
       ,s1=s1
       ,s2=s2
       ,n1=n1
       ,n2=n2
       ,s_pooled=s_pooled
       ,d=d
       ,vd=vd
       ,sed=sed
       ,ci_upper=ci_upper
       ,ci_lower=ci_lower
       ,p=p2
       ,d_paired=d_paired)
     
}

supp_s2good_M1_stats <- s_pooled_fun()
d <- supp_s2good_M1_stats$d
d

save(supp_s2good_rtot_stats
     , supp_s2good_M1_stats
     , supp_s2bad_rtot_stats
     , supp_s2bad_M1_stats, file = "supp_S2_effect_stats.RData")


```



```{r}

y <- supp_s2good_M1_stats

icc <- performance::icc(model1)
icc$ICC_unadjusted

names_for_table <- c("b", "SE", "df", "t", "p"
  , "Mdiag", "SDdiag", "Mnond", "SDnond"
  , "d", "upper","lower","variance","ICC")

results_coef_for_table <- results_coef[2,]
class(results_coef_for_table)

supp_s2good_M1_for_table <- 
  `colnames<-`(
    cbind.data.frame(results_coef_for_table
                     , y$x1, y$s1, y$x2, y$s2
                     , y$d_paired, y$ci_upper, y$ci_lower
                     , y$vd, icc$ICC_unadjusted)
    ,names_for_table)

rm(y)

supp_s2good_M1_vars <- as.data.frame(VarCorr(model1))


save(supp_s2good_rtot_for_table, supp_s2good_M1_for_table, supp_s2good_rtot_vars, supp_s2good_M1_vars, file = "supp_s2good_table_data.RData")


```


We conducted a linear-mixed-effects model to test if condition influenced MM-1 responses. Our outcome measure was MM-1, our predictor variable was condition; we allowed intercepts and the effect of condition to vary across participants. Overall, the model significantly predicted participants responses, and provided a better fit for the data than the baseline model, $\chi$^2^(`r results_anova$Df[2]`) = `r results_anova$Chisq[2]`, *p* `r paste(p_report(p1))`. Condition significantly influenced MM-1 responses *F*(`r aov1$NumDF[1]`, `r round(aov1$DenDF[1])`) = `r f3`, *p* `r paste(p_report(p3))`, and was a significant predictor in the model $b$ = `r results_coef$Estimate[2]` ($\beta$ = `r b_std`), *t*(`r round(results_coef$df[2])`) = `r t1`, *p* `r paste(p_report(p2))`, (*d* = `r round(d, digits=2)`), see Figure\ \@ref(fig:StudyS2bothconditionplot).



```{r}
x <- df3
x$Scenario <- dplyr::recode(x$scenario
              , "francis" = "Francis"
              , "alex" = "Alex"
              , "sam" = "Sam"
              , "robin" = "Robin")

```


```{r}


x_error_bars <- Rmisc::summarySE(x, measurevar="R_tot", groupvars=c("condition", "Scenario"))
x_error_bars

g <- ggplot(x,
            aes(x = condition, y = R_tot
                , fill=factor(condition
                              ,labels=c("Diagnostic","Non-Diagnostic")
                )
               # , color=factor(Valence)
            )) + 
  
  #scale_y_continuous(limits = c(-0, 140))+
  #, labels = percent_format()
  # )+ 
  ggdist::stat_halfeye(
    adjust = 2.1, 
    width = .35, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA,
    position = position_dodge(width=0.9)
  ) + 
  geom_boxplot(
    width = .13, 
    outlier.shape = NA
    , position = position_dodge(width=.8)
    , show_guide = FALSE
  ) +
  ## add justified jitter from the {gghalves} package
  gghalves::geom_half_point(
    aes(color=factor(condition
                     #                   ,labels=c("Means","Side-Effect")
    )
    ),
    position = position_dodge(width=4.3),
    ## draw jitter on the left
    side = "l", 
    ## control range of jitter
    range_scale = .4, 
    ## add some transparency
    alpha = .42,
    size = .1,
    show_guide = FALSE
  )+
  stat_summary(
    aes(color=factor(Condition
                                          #,labels=c("Gratitude","No Gratitude")
    )
    ),
    geom = "point",
    fun = "mean",
    col = "black",
    size = 1,
    shape = 16, #24,
    position = position_dodge(width=.2)
   # , justification = -.2
    , fill = "black"
    ,show_guide = FALSE
  )+
  geom_errorbar(data = x_error_bars,aes(ymin=R_tot-se
                                        , ymax=R_tot+se
                                        , width=.05#, position=pd
                                        # , fill= "black" #factor(condition
                                        #     ,labels=c("Means","Side-Effect")
                                        #)
  )
  , position = position_dodge(width=6.12)
  ) +
  #facet_grid(cols = vars(means))+
  xlab("Information Type") +
  ylab("MPS-4")+
  scale_x_discrete(
    labels=c("Diagnostic","Non-Diagnostic")
  ) +
  scale_y_continuous(limits = c(-.0,7)
                     , breaks = seq(0,7, by = 1)  #  c(0:)
                     #                    , labels=c(" ", "1", "2", "3","4","5","6","7")
  ) +
  scale_fill_grey(start = .3, end = .6) +
  scale_color_grey(start = .3, end = .6) +
  guides(
    fill=guide_legend(title = "Information Type")
   # , color=guide_legend(title="Valence")
    , shape="none"
  )+
  # facet_grid(cols = vars(Valence))+
  #labs(fill="Means/Side-Effect") +
  # 
  # geom_text(#family = "Times",
  #           size=4.2,
  #           aes( label = scales::percent(test$perc),
  #                y= test$perc ),
  #           stat= "identity",
  #           vjust = -.5,
  #           position = position_dodge(.9),
  #           fontface='plain'
  #           )+
#theme_apa() +
  theme_bw() +
  facet_grid(cols = vars(Scenario)) +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
                                size=12
                                ),
        legend.text=element_text(#family="Times",
                                 size=8
                                 ),
          legend.title=element_text(#family="Times",
                                    size=10
                                    ),
          axis.text=element_text(#family="Times",
                                 colour = "black",
                                 size=8
                                 ),
          axis.ticks.x = element_blank(),
          axis.title=element_text(#family="Times",
                                  size=12
                                  ),
          strip.text=element_text(#family = "Times",
                                  size = 12
                                  ),
         # strip.background = element_rect(fill = "white"),
          legend.position="none")

mps4plot <- g


```



```{r}


x_error_bars <- Rmisc::summarySE(x, measurevar="M1", groupvars=c("condition", "Scenario"))
x_error_bars

g <- ggplot(x,
            aes(x = condition, y = M1
                , fill=factor(condition
                              ,labels=c("Diagnostic","Non-Diagnostic")
                )
               # , color=factor(Valence)
            )) + 
  
  #scale_y_continuous(limits = c(-0, 140))+
  #, labels = percent_format()
  # )+ 
  ggdist::stat_halfeye(
    adjust = 2.1, 
    width = .35, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA,
    position = position_dodge(width=0.9)
  ) + 
  geom_boxplot(
    width = .13, 
    outlier.shape = NA
    , position = position_dodge(width=.8)
    , show_guide = FALSE
  ) +
  ## add justified jitter from the {gghalves} package
  gghalves::geom_half_point(
    aes(color=factor(condition
                     #                   ,labels=c("Means","Side-Effect")
    )
    ),
    position = position_dodge(width=4.3),
    ## draw jitter on the left
    side = "l", 
    ## control range of jitter
    range_scale = .4, 
    ## add some transparency
    alpha = .42,
    size = .1,
    show_guide = FALSE
  )+
  stat_summary(
    aes(color=factor(Condition
                                          #,labels=c("Gratitude","No Gratitude")
    )
    ),
    geom = "point",
    fun = "mean",
    col = "black",
    size = 1,
    shape = 16, #24,
    position = position_dodge(width=.2)
   # , justification = -.2
    , fill = "black"
    ,show_guide = FALSE
  )+
  geom_errorbar(data = x_error_bars,aes(ymin=M1-se
                                        , ymax=M1+se
                                        , width=.05#, position=pd
                                        # , fill= "black" #factor(condition
                                        #     ,labels=c("Means","Side-Effect")
                                        #)
  )
  , position = position_dodge(width=6.12)
  ) +
  #facet_grid(cols = vars(means))+
  xlab("Information Type") +
  ylab("MM-1")+
  scale_x_discrete(
    labels=c("Diagnostic","Non-Diagnostic")
  ) +
  scale_y_continuous(limits = c(-.0,100)
                     , breaks = seq(0,100, by = 10)  #  c(0:)
                     #                    , labels=c(" ", "1", "2", "3","4","5","6","7")
  ) +
  scale_fill_grey(start = .3, end = .6) +
  scale_color_grey(start = .3, end = .6) +
  guides(
    fill=guide_legend(title = "Information Type")
    , color=guide_legend(title="Valence")
    , shape="none"
  )+
  # facet_grid(cols = vars(Valence))+
  #labs(fill="Means/Side-Effect") +
  # 
  # geom_text(#family = "Times",
  #           size=4.2,
  #           aes( label = scales::percent(test$perc),
  #                y= test$perc ),
  #           stat= "identity",
  #           vjust = -.5,
  #           position = position_dodge(.9),
  #           fontface='plain'
  #           )+
#theme_apa() +
  facet_grid(cols = vars(Scenario)) +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
                                size=12
                                ),
        legend.text=element_text(#family="Times",
                                 size=8
                                 ),
          legend.title=element_text(#family="Times",
                                    size=10
                                    ),
          axis.text=element_text(#family="Times",
                                 colour = "black",
                                 size=8
                                 ),
          axis.ticks.x = element_blank(),
          axis.title=element_text(#family="Times",
                                  size=12
                                  ),
          strip.text=element_text(#family = "Times",
                                  size = 12
                                  ),
         # strip.background = element_rect(fill = "white"),
          legend.position="none")
g

M1plot <- g


```


```{r}


x_error_bars <- Rmisc::summarySE(x, measurevar="M1R_tot", groupvars=c("condition", "Scenario"))
x_error_bars

g <- ggplot(x,
            aes(x = condition, y = M1R_tot
                , fill=factor(condition
                              ,labels=c("Diagnostic","Non-Diagnostic")
                )
               # , color=factor(Valence)
            )) + 
  
  #scale_y_continuous(limits = c(-0, 140))+
  #, labels = percent_format()
  # )+ 
  ggdist::stat_halfeye(
    adjust = 2.1, 
    width = .35, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA,
    position = position_dodge(width=0.9)
  ) + 
  geom_boxplot(
    width = .13, 
    outlier.shape = NA
    , position = position_dodge(width=.8)
    , show_guide = FALSE
  ) +
  ## add justified jitter from the {gghalves} package
  gghalves::geom_half_point(
    aes(color=factor(condition
                     #                   ,labels=c("Means","Side-Effect")
    )
    ),
    position = position_dodge(width=4.3),
    ## draw jitter on the left
    side = "l", 
    ## control range of jitter
    range_scale = .4, 
    ## add some transparency
    alpha = .42,
    size = .1,
    show_guide = FALSE
  )+
  geom_point(data=x_error_bars, inherit.aes = FALSE
             , aes(x=condition, y=M1R_tot)
             , size=.5
    )+
  # stat_summary(
  #   aes(color=factor(Condition
  #                                         #,labels=c("Gratitude","No Gratitude")
  #   )
  #   ),
  #   geom = "point",
  #   fun = "mean",
  #   col = "black",
  #   size = 1,
  #   shape = 16, #24,
  #   position = position_dodge(width=.2)
  #  # , justification = -.2
  #   , fill = "black"
  #   ,show_guide = FALSE
  # )+
  geom_errorbar(data = x_error_bars,aes(ymin=M1R_tot-se
                                        , ymax=M1R_tot+se
                                        , width=.05#, position=pd
                                        # , fill= "black" #factor(condition
                                        #     ,labels=c("Means","Side-Effect")
                                        #)
  )
  , position = position_dodge(width=6.12)
  ) +
  #facet_grid(cols = vars(means))+
  xlab("Information Type") +
  ylab("Combined")+
  scale_x_discrete(
    labels=c("Diagnostic","Non-Diagnostic")
  ) +
  scale_y_continuous(limits = c(-2.5,1.2)
                     , breaks = seq(-2.5,1.2, by = .5)  #  c(0:)
                     #                    , labels=c(" ", "1", "2", "3","4","5","6","7")
  ) +
  scale_fill_grey(start = .3, end = .6) +
  scale_color_grey(start = .3, end = .6) +
  guides(
    fill=guide_legend(title = "Information Type")
    , color=guide_legend(title="Valence")
    , shape="none"
  )+
  facet_grid(cols = vars(Scenario)) +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
                                size=12
                                ),
        legend.text=element_text(#family="Times",
                                 size=8
                                 ),
          legend.title=element_text(#family="Times",
                                    size=10
                                    ),
          axis.text=element_text(#family="Times",
                                 colour = "black",
                                 size=8
                                 ),
          axis.ticks.x = element_blank(),
          axis.title=element_text(#family="Times",
                                  size=12
                                  ),
          strip.text=element_text(#family = "Times",
                                  size = 12
                                  ),
         # strip.background = element_rect(fill = "white"),
          legend.position="none")


mBothPlot <- g

```

```{r}
figure <- ggarrange(mps4plot
                    , M1plot
                    , mBothPlot
                    #,labels = c("A")
                    , ncol = 1
                    , nrow = 3
                    , widths = c(0.485, 0.5))
figure
```


```{r StudyS2AllscenariosPlot, fig.cap="Study S2: Differences in moral perception for each description", include=TRUE, fig.height=8, out.width = "\\textwidth", fig.pos = "!h"}

suppressWarnings(print(figure))

```


## Study S2: Differences between the descriptions

Again, we conducted separate analyses to investigate of condition on responses to each scenario individually. The responses for each scenario across each measure depending on condition are displayed in Figure\ \@ref(fig:StudyS2AllscenariosPlot).



```{r}

x <- sam
d1 <- lsr::cohensD(R_tot~condition,x)
t1 <- t.test(R_tot~condition,x)
t1$parameter
t1$statistic
t1$p.value

d2 <- lsr::cohensD(M1~condition,x)
t2 <- t.test(M1~condition,x)


d3 <- lsr::cohensD(M1R_tot~condition,x)
t3 <- t.test(M1R_tot~condition,x)

xd <- x[which(x$condition=="diagnostic"),]
xnond <- x[which(x$condition=="non-diagnostic"),]
```


For *Sam* (*good*), MPS-4 scores were significantly lower in the non-diagnostic condition (*M* = `r mean(xnond$R_tot)`, *SD* = `r sd(xnond$R_tot)`), than in the diagnostic condition (*M* = `r mean(xd$R_tot)`, *SD* = `r sd(xd$R_tot)`), *t*(`r t1$parameter`) = `r t1$statistic`, *p* `r paste(p_report(t1$p.value))`, *d* = `r d1`; Similarly, MM-1 ratings were significantly lower in the non-diagnostic condition (*M* = `r mean(xnond$M1)`, *SD* = `r sd(xnond$M1)`), than in the diagnostic condition (*M* = `r mean(xd$M1)`, *SD* = `r sd(xd$M1)`), *t*(`r t2$parameter`) = `r t2$statistic`, *p* `r paste(p_report(t2$p.value))`, *d* = `r d2`. For the combined measure ratings were also lower in the non-diagnostic condition (*M* = `r mean(xnond$M1R_tot)`, *SD* = `r sd(xnond$M1R_tot)`), than in the diagnostic condition (*M* = `r mean(xd$M1R_tot)`, *SD* = `r sd(xd$M1R_tot)`), *t*(`r t3$parameter`) = `r t3$statistic`, *p* `r paste(p_report(t3$p.value))`, *d* = `r d3`.


```{r}

x <- robin
d1 <- lsr::cohensD(R_tot~condition,x)
t1 <- t.test(R_tot~condition,x)
t1$parameter
t1$statistic
t1$p.value

d2 <- lsr::cohensD(M1~condition,x)
t2 <- t.test(M1~condition,x)


d3 <- lsr::cohensD(M1R_tot~condition,x)
t3 <- t.test(M1R_tot~condition,x)

xd <- x[which(x$condition=="diagnostic"),]
xnond <- x[which(x$condition=="non-diagnostic"),]
```

For *Robin* (*good*), MPS-4 scores were not significantly different for the non-diagnostic condition (*M* = `r mean(xnond$R_tot)`, *SD* = `r sd(xnond$R_tot)`), than in the diagnostic condition (*M* = `r mean(xd$R_tot)`, *SD* = `r sd(xd$R_tot)`), *t*(`r t1$parameter`) = `r t1$statistic`, *p* `r paste(p_report(t1$p.value))`, *d* = `r d1`; MM-1 ratings were similar in the non-diagnostic condition (*M* = `r mean(xnond$M1)`, *SD* = `r sd(xnond$M1)`), and in the diagnostic condition (*M* = `r mean(xd$M1)`, *SD* = `r sd(xd$M1)`), *t*(`r t2$parameter`) = `r t2$statistic`, *p* `r paste(p_report(t2$p.value))`, *d* = `r d2`. For the combined measure ratings were also similar in the non-diagnostic condition (*M* = `r mean(xnond$M1R_tot)`, *SD* = `r sd(xnond$M1R_tot)`), than in the diagnostic condition (*M* = `r mean(xd$M1R_tot)`, *SD* = `r sd(xd$M1R_tot)`), *t*(`r t3$parameter`) = `r t3$statistic`, *p* `r paste(p_report(t3$p.value))`, *d* = `r d3`.


```{r}

x <- alex
d1 <- lsr::cohensD(R_tot~condition,x)
t1 <- t.test(R_tot~condition,x)
t1$parameter
t1$statistic
t1$p.value

d2 <- lsr::cohensD(M1~condition,x)
t2 <- t.test(M1~condition,x)


d3 <- lsr::cohensD(M1R_tot~condition,x)
t3 <- t.test(M1R_tot~condition,x)

xd <- x[which(x$condition=="diagnostic"),]
xnond <- x[which(x$condition=="non-diagnostic"),]
```

For *Alex* (*bad*), MPS-4 scores were not significantly different for the non-diagnostic condition (*M* = `r mean(xnond$R_tot)`, *SD* = `r sd(xnond$R_tot)`), than in the diagnostic condition (*M* = `r mean(xd$R_tot)`, *SD* = `r sd(xd$R_tot)`), *t*(`r t1$parameter`) = `r t1$statistic`, *p* `r paste(p_report(t1$p.value))`, *d* = `r d1`; MM-1 ratings were similar in the non-diagnostic condition (*M* = `r mean(xnond$M1)`, *SD* = `r sd(xnond$M1)`), and in the diagnostic condition (*M* = `r mean(xd$M1)`, *SD* = `r sd(xd$M1)`), *t*(`r t2$parameter`) = `r t2$statistic`, *p* `r paste(p_report(t2$p.value))`, *d* = `r d2`. For the combined measure ratings were also similar in the non-diagnostic condition (*M* = `r mean(xnond$M1R_tot)`, *SD* = `r sd(xnond$M1R_tot)`), and in the diagnostic condition (*M* = `r mean(xd$M1R_tot)`, *SD* = `r sd(xd$M1R_tot)`), *t*(`r t3$parameter`) = `r t3$statistic`, *p* `r paste(p_report(t3$p.value))`, *d* = `r d3`.


```{r}

x <- francis
d1 <- lsr::cohensD(R_tot~condition,x)
t1 <- t.test(R_tot~condition,x)
t1$parameter
t1$statistic
t1$p.value

d2 <- lsr::cohensD(M1~condition,x)
t2 <- t.test(M1~condition,x)


d3 <- lsr::cohensD(M1R_tot~condition,x)
t3 <- t.test(M1R_tot~condition,x)

xd <- x[which(x$condition=="diagnostic"),]
xnond <- x[which(x$condition=="non-diagnostic"),]
```

For *Francis* (*bad*), MPS-4 scores were not significantly different for the non-diagnostic condition (*M* = `r mean(xnond$R_tot)`, *SD* = `r sd(xnond$R_tot)`), than in the diagnostic condition (*M* = `r mean(xd$R_tot)`, *SD* = `r sd(xd$R_tot)`), *t*(`r t1$parameter`) = `r t1$statistic`, *p* `r paste(p_report(t1$p.value))`, *d* = `r d1`; MM-1 ratings were not significantly different in the non-diagnostic condition (*M* = `r mean(xnond$M1)`, *SD* = `r sd(xnond$M1)`), than in the diagnostic condition (*M* = `r mean(xd$M1)`, *SD* = `r sd(xd$M1)`), *t*(`r t2$parameter`) = `r t2$statistic`, *p* `r paste(p_report(t2$p.value))`, *d* = `r d2`. For the combined measure ratings were also similar in the non-diagnostic condition (*M* = `r mean(xnond$M1R_tot)`, *SD* = `r sd(xnond$M1R_tot)`), and in the diagnostic condition (*M* = `r mean(xd$M1R_tot)`, *SD* = `r sd(xd$M1R_tot)`), *t*(`r t3$parameter`) = `r t3$statistic`, *p* `r paste(p_report(t3$p.value))`, *d* = `r d3`.
